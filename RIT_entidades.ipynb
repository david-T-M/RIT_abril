{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/rit/lib/python3.9/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils as ut # esta librería tiene funciones para poder obtener un procesamiento del <T,H>\n",
    "import spacy\n",
    "import mutual_info as mi\n",
    "import time\n",
    "from scipy.stats import wasserstein_distance,entropy\n",
    "import sys\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conceptnet_lite\n",
    "conceptnet_lite.connect(\"../OPENAI/data/conceptnet.db\")\n",
    "from conceptnet_lite import Label, edges_for, edges_between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_distancia(texto_v,hipotesis_v,texto_t,texto_h,b_col,b_index):\n",
    "    lista_l=[]\n",
    "    for i in range(len(texto_t)):\n",
    "        lista=[]\n",
    "        for j in range(len(texto_h)):\n",
    "            lista.append(np.linalg.norm(texto_v[i] - hipotesis_v[j]))#*wasserstein_distance(texto_2[i],hipotesis_2[j]))\n",
    "        lista_l.append(lista)\n",
    "    df_distEuc=pd.DataFrame(lista_l,index=texto_t,columns=texto_h)\n",
    "    df_distEuc=df_distEuc.drop(b_col[1:],axis=1)\n",
    "    df_distEuc=df_distEuc.drop(b_index[1:],axis=0)\n",
    "    return df_distEuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_mutual_inf(texto_v,hipotesis_v,texto_t,texto_h):  \n",
    "    lista_l=[]\n",
    "    lista_muinfor=[]   \n",
    "    for i in range(len(texto_t)):\n",
    "        lista=[]\n",
    "        lista_mu=[]\n",
    "        for j in range(len(texto_h)):\n",
    "            lista.append(wasserstein_distance(texto_v[i],hipotesis_v[j]))\n",
    "            lista_mu.append(mi.mutual_information_2d(np.array(texto_v[i]),np.array(hipotesis_v[j])))\n",
    "        lista_l.append(lista)\n",
    "        lista_muinfor.append(lista_mu)\n",
    "    DFmearth=pd.DataFrame(lista_l,index=texto_t,columns=texto_h)\n",
    "    DFmutual_inf=pd.DataFrame(lista_muinfor,index=texto_t,columns=texto_h)\n",
    "    return DFmearth,DFmutual_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropia(X):\n",
    "    \"\"\"Devuelve el valor de entropia de una muestra de datos\"\"\" \n",
    "    probs = [np.mean(X == valor) for valor in set(X)]\n",
    "    print(\"Valores para entropia\",set(X))\n",
    "    print(\"Probabilidades\",probs)\n",
    "    #return round(sum(-p * np.log2(p) for p in probs), 3)\n",
    "    return entropy(probs,base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores para entropia {0, 1, 2, 3}\n",
      "Probabilidades [0.09090909090909091, 0.09090909090909091, 0.7272727272727273, 0.09090909090909091]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2776134368191157"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropia(np.array([1,2,2,2,2,2,2,2,2,0,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kullback_leibler(X,Y):\n",
    "    \"\"\"Devuelve el valor de entropia de una muestra de datos\"\"\" \n",
    "    probsX = [np.mean(X == valor) for valor in set(X)]\n",
    "    print(\"Valores para entropia\",set(X))\n",
    "    print(\"Probabilidades\",probsX)\n",
    "    probsY = [np.mean(Y == valor) for valor in set(X)]\n",
    "    print(\"Valores para entropia\",set(X))\n",
    "    print(\"Probabilidades\",probsY)\n",
    "    #return round(sum(-p * np.log2(p) for p in probs), 3)\n",
    "    return entropy(probsY,probsX,base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores para entropia {1, 2, 3}\n",
      "Probabilidades [0.2, 0.6, 0.2]\n",
      "Valores para entropia {1, 2, 3}\n",
      "Probabilidades [0.25, 0.75, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32192809488736235"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kullback_leibler(np.array([1,2,2,2,3]),np.array([1,2,2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "relaciones_generales=[\"is_a\",\"part_of\",\"used_for\", \"capable_of\", \"at_location\",\"etymologically_related_to\",\"manner_of\",\"has_a\",\"derived_from\",\"has_property\",\"form_of\",\"causes\",\"has_prerequisite\",\"has_subevent\",\"has_first_subevent\"]\n",
    "relaciones_especificas=[\"is_a\",\"manner_of\",\"has_a\",\"derived_from\",\"has_property\",\"form_of\",\"causes\",\"has_prerequisite\",\"has_subevent\",\"has_first_subevent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_synonyms(word):\n",
    "    sinonimos=set()\n",
    "    try:\n",
    "        for e in edges_for(Label.get(text=word, language='en').concepts, same_language=True):\n",
    "            if e.relation.name == \"synonym\":\n",
    "                if word== e.start.text:\n",
    "                    sinonimos.add(e.end.text)\n",
    "                elif word== e.end.text:\n",
    "                    sinonimos.add(e.start.text)\n",
    "    except:\n",
    "        pass\n",
    "    sinonimos.add(word)\n",
    "    return sinonimos\n",
    "\n",
    "def bag_of_antonyms(word):\n",
    "    antonimos=set()\n",
    "    try:\n",
    "        for e in edges_for(Label.get(text=word, language='en').concepts, same_language=True):\n",
    "            if e.relation.name in [\"antonym\",\"distinc_from\"]:\n",
    "                if word== e.start.text:\n",
    "                    antonimos.add(e.end.text)\n",
    "                elif word== e.end.text:\n",
    "                    antonimos.add(e.start.text)\n",
    "    except:\n",
    "        pass\n",
    "    return antonimos\n",
    "\n",
    "def bag_of_hyperonyms(word):\n",
    "    hiperonimos=set()\n",
    "    try:\n",
    "        for e in edges_for(Label.get(text=word, language='en').concepts, same_language=True):\n",
    "            if e.relation.name in relaciones_generales:\n",
    "                if word== e.start.text:\n",
    "                    hiperonimos.add(e.end.text)\n",
    "    except:\n",
    "        pass\n",
    "    return hiperonimos\n",
    "\n",
    "def bag_of_hyponyms(word):\n",
    "    hiponimos=set()\n",
    "    try:\n",
    "        for e in edges_for(Label.get(text=word, language='en').concepts, same_language=True):\n",
    "            if e.relation.name in relaciones_especificas:\n",
    "                if word== e.end.text:\n",
    "                    hiponimos.add(e.start.text)\n",
    "                    #print(e.relation.name,e.start.text)\n",
    "    except:\n",
    "        pass\n",
    "    return hiponimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaro_distance(s1, s2,sinT,sinH,HipT,hipH) :\n",
    "    bandera=True\n",
    "\n",
    "    # Length of two strings\n",
    "    len1 = len(s1)\n",
    "    len2 = len(s2)\n",
    "\n",
    "    # If the listas de tokens are equal \n",
    "    if len1==len2:\n",
    "        for i in range(len1):\n",
    "            if s1[i]!=s2[i]:\n",
    "                bandera=False\n",
    "                break\n",
    "        if (bandera):\n",
    "            return 1.0; \n",
    " \n",
    "    if (len1 == 0 or len2 == 0) :\n",
    "        return 0.0; \n",
    " \n",
    "    # Maximum distance upto which matching \n",
    "    # is allowed \n",
    "    max_dist = (max(len(s1), len(s2)) // 2 )-1 ; \n",
    " \n",
    "    # Count of matches \n",
    "    match = 0; \n",
    " \n",
    "    # Hash for matches \n",
    "    hash_s1 = [0] * len(s1)\n",
    "    hash_s2 = [0] * len(s2)\n",
    " \n",
    "    # Traverse through the first string \n",
    "    for i in range(len1):\n",
    " \n",
    "        # Check if there is any matches\n",
    "        for j in range(max(0, i - max_dist), \n",
    "                       min(len2, i + max_dist + 1)):\n",
    "            print(s1[i],s2[j])\n",
    "            # If there is a match or is contain in a bag of sinomys of tk\n",
    "            if ((s1[i] == s2[j] or s1[i] in sinH[j] or s2[j] in sinT[i]) and hash_s2[j] == 0) : \n",
    "                print(s1[i],s2[j],\"sinonimos\")\n",
    "                hash_s1[i] += 1; \n",
    "                hash_s2[j] += 1; \n",
    "                match += 1; \n",
    "                break\n",
    "            elif ((s1[i] in hipH[j] or len((sinT[i]).intersection(hipH[j]))>0) and hash_s2[j] == 0):\n",
    "                print(\"hiponimos\",s2[j],s1[i],(sinT[i]).intersection(hipH[j]))\n",
    "                hash_s1[i] += 1; \n",
    "                hash_s2[j] += 1; \n",
    "                match += 1; \n",
    "                break\n",
    "            elif ((s2[j] in HipT[i] or len((sinH[j]).intersection(HipT[i]))>0) and hash_s2[j] == 0): \n",
    "                print(\"hiperonimos sobre sinonimos\",s2[j],s1[i])\n",
    "                hash_s1[i] += 1; \n",
    "                hash_s2[j] += 1; \n",
    "                match += 1; \n",
    "                break\n",
    "            # elif len((hipH[j]).intersection(HipT[i]))>0 and hash_s2[j] == 0: \n",
    "            #     print(\"hiperonimos3\",s2[j],s1[i],(hipH[j]).intersection(HipT[i]))\n",
    "            #     hash_s1[i] += 1; \n",
    "            #     hash_s2[j] += 1; \n",
    "            #     match += 1; \n",
    "            #     break\n",
    "            \n",
    "    print(hash_s1)\n",
    "    print(hash_s2)\n",
    "    print(match)\n",
    "    # If there is no match \n",
    "    if (match == 0) :\n",
    "        return 0.0; \n",
    " \n",
    "    # Number of transpositions \n",
    "    t = 0; \n",
    " \n",
    "    point = 0; \n",
    " \n",
    "    # Count number of occurrences \n",
    "    # where two characters match but \n",
    "    # there is a third matched character \n",
    "    # in between the indices \n",
    "    for i in range(len1) : \n",
    "        if (hash_s1[i]) :\n",
    "            # Find the next matched character \n",
    "            # in second string \n",
    "            while (hash_s2[point] == 0) :\n",
    "                point += 1; \n",
    " \n",
    "            if (s1[i] != s2[point]) :\n",
    "                point += 1\n",
    "                t += 1\n",
    "            else :\n",
    "                point += 1    \n",
    "    t /= 2; \n",
    "    #Return the Jaro Similarity \n",
    "    return match / len2; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relacion_entailment(wt,wh):\n",
    "    try:\n",
    "        concepts_wt = Label.get(text=wt, language='en').concepts\n",
    "        concepts_wh = Label.get(text=wh, language='en').concepts\n",
    "        for e in edges_between(concepts_wt, concepts_wh):\n",
    "            if wt == e.start.text and e.relation.name in relaciones_generales:\n",
    "                print(e.start.text, \"-\", e.end.text, \"|\", e.relation.name,e)\n",
    "                return True\n",
    "    except:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def relacion_noentailment(wt,wh):\n",
    "    try:\n",
    "        concepts_wt = Label.get(text=wt, language='en').concepts\n",
    "        concepts_wh = Label.get(text=wh, language='en').concepts\n",
    "        for e in edges_between(concepts_wt, concepts_wh):\n",
    "            if wt == e.start.text and e.relation.name in [\"distinct_from\",\"antonym\"]:\n",
    "                print(e.start.text, \"-\", e.end.text, \"|\", e.relation.name,e)\n",
    "                return True\n",
    "    except:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def relacion_conceptual(wt,wh):\n",
    "    try:\n",
    "        concepts_wt = Label.get(text=wt, language='en').concepts\n",
    "        concepts_wh = Label.get(text=wh, language='en').concepts\n",
    "        for e in edges_between(concepts_wt, concepts_wh,two_way=True):\n",
    "            if wt==e.end.text and e.relation.name in relaciones_generales:\n",
    "                print(e.start.text, \"-\", e.end.text, \"|\", e.relation.name,e)\n",
    "                return True\n",
    "            elif e.relation.name in [\"related_to\",\"similar_to\"]:\n",
    "                print(e.start.text, \"-\", e.end.text, \"|\", e.relation.name,e)\n",
    "                return True\n",
    "    except:\n",
    "        pass\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negacion(nlp,texto):\n",
    "    b=1.0\n",
    "    if (type(texto)==type(b) or texto==\"\" or texto==\"n/a\" or texto==\"nan\"):\n",
    "        return 0,\"\"\n",
    "    doc = nlp(texto.lower())\n",
    "    for token in doc:\n",
    "        if(token.dep_==\"neg\"):\n",
    "            return 1, token.head.lemma_\n",
    "    return 0,\"\"\n",
    "\n",
    "def representacion_entidades(nlp,texto):\n",
    "    dir_sust=dict()\n",
    "    palabras=[]\n",
    "    b=1.0\n",
    "    if (type(texto)==type(b) or texto==\"\" or texto==\"n/a\" or texto==\"nan\"):\n",
    "        return dir_sust,palabras\n",
    "    doc =nlp(texto.lower())\n",
    "    for token in doc:\n",
    "        if token.dep_ in tags:\n",
    "            #print(token.text, token.lemma_, token.pos_,token.dep_,token.head.text,token.head.lemma_, token.head.pos_,\n",
    "            #    [child for child in token.children])\n",
    "            #sustantivos.append(token.head.lemma_)\n",
    "            if token.head.lemma_ in dir_sust:\n",
    "                if dir_sust[token.head.lemma_]==\"NA\":\n",
    "                    dir_sust[token.head.lemma_]=token.lemma_\n",
    "                    if token.head not in palabras:\n",
    "                        palabras.append(token.head)\n",
    "                else:\n",
    "                    dir_sust[token.head.lemma_]=dir_sust[token.head.lemma_]+\",\"+token.lemma_\n",
    "                    if token.head not in palabras:\n",
    "                        palabras.append(token.head)\n",
    "            else:\n",
    "                dir_sust[token.head.lemma_]=token.lemma_\n",
    "                if token.head not in palabras:\n",
    "                    palabras.append(token.head)\n",
    "        elif token.pos_ in [\"NOUN\",\"PROPN\"]:\n",
    "            #print(token.text,token.lemma_, token.pos_,token.dep_)\n",
    "            #sustantivos.append(token.lemma_)\n",
    "            if token.lemma_ not in dir_sust:\n",
    "                dir_sust[token.lemma_]=\"NA\"\n",
    "                if token not in palabras:\n",
    "                    palabras.append(token)\n",
    "        elif token.pos_ in [\"VERB\"]:\n",
    "            #print(token.text, token.lemma_,token.pos_,token.dep_)\n",
    "            #sustantivos.append(token.lemma_)\n",
    "            if token.lemma_ not in dir_sust:\n",
    "                dir_sust[token.lemma_]=\"NA\"\n",
    "                if token not in palabras:\n",
    "                    palabras.append(token)\n",
    "        else:\n",
    "            print(token.text)\n",
    "    return dir_sust,palabras\n",
    "\n",
    "def representacion2(nlp,texto):\n",
    "    doc = nlp(texto.lower())\n",
    "    dir_sust=dict()\n",
    "    palabras=[]\n",
    "    noun_phrase= [chunk.lemma_ for chunk in doc.noun_chunks]\n",
    "    verbs = [token.lemma_ for token in doc if token.pos_ == \"VERB\"]\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if chunk.root.lemma_!=chunk.lemma_:\n",
    "            dir_sust[chunk.root.lemma_]=','.join(chunk.lemma_.split()[:-1])\n",
    "        else:\n",
    "            dir_sust[chunk.root.lemma_]=\"NA\"\n",
    "    palabras.extend([chunk.root.lemma_ for chunk in doc.noun_chunks])\n",
    "    palabras.extend(verbs)\n",
    "    return dir_sust,palabras\n",
    "\n",
    "deps_tags=[\"relcl\",\"prep\",\"amod\",\"compound\",\"pobj\",\"conj\",\"nsubj\",\"advcl\",\"dobj\",\"neg\",'acomp',\"attr\", 'nummod',\"oprd\",\"npadvmod\"]\n",
    "palabras_no=[\"wear\",\"dress\",\"clothe\"]\n",
    "def representacion(nlp,texto):\n",
    "    dir_sust=dict()\n",
    "    palabras=[]\n",
    "    b=1.0\n",
    "    if (type(texto)==type(b) or texto==\"\" or texto==\"n/a\" or texto==\"nan\"):\n",
    "        return dir_sust,palabras\n",
    "    doc =nlp(texto)\n",
    "    # poses=[]\n",
    "    # tokens=[]\n",
    "    # lemmas=[]\n",
    "    # children=[]\n",
    "    # verb_vincu=[]\n",
    "    # deps=[]\n",
    "    dir_sust=dict()\n",
    "    palabras=[]\n",
    "    frase=\"\"\n",
    "    anterior=\"det\"\n",
    "    nsubj=\"\"\n",
    "    for token in doc:\n",
    "        #print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "        #    [child for child in token.children])\n",
    "        # poses.append(token.pos_)\n",
    "        # tokens.append(token.text)\n",
    "        # lemmas.append(token.lemma_)\n",
    "        # verb_vincu.append(token.head.lemma_)\n",
    "        # deps.append(token.dep_)\n",
    "        # children.append([child for child in token.children])\n",
    "        # print(token.text,token.pos_,token.dep_)\n",
    "        if token.lemma_ not in palabras_no:\n",
    "            if token.dep_ in deps_tags or (token.dep_==\"ROOT\" and token.pos_==\"NOUN\"):\n",
    "                if token.dep_==\"nsubj\": \n",
    "                    if nsubj==\"\":\n",
    "                        frase= frase + \" \" + token.lemma_ \n",
    "                        nsubj=token.lemma_\n",
    "                    else:\n",
    "                        if frase!=\"\":\n",
    "                            palabras.append(frase.split()[-1])\n",
    "                            if len(frase.split())>1:\n",
    "                                dir_sust[frase.split()[-1]]=','.join(frase.split()[0:-1])\n",
    "                            else:\n",
    "                                dir_sust[frase.split()[-1]]=\"NA\"\n",
    "                        frase=\"\"\n",
    "                elif token.dep_==\"prep\":\n",
    "                    if token.lemma_ not in [\"in\",\"at\",\"on\",\"with\",\"from\",\"to\",\"for\",\"since\"]:    \n",
    "                        frase= frase + token.lemma_ + \" \"\n",
    "                    else:\n",
    "                        if frase!=\"\":\n",
    "                            palabras.append(frase.split()[-1])\n",
    "                            if len(frase.split())>1:\n",
    "                                dir_sust[frase.split()[-1]]=','.join(frase.split()[0:-1])\n",
    "                            else:\n",
    "                                dir_sust[frase.split()[-1]]=\"NA\"\n",
    "                        frase=\"\"\n",
    "                elif token.dep_==\"neg\":\n",
    "                    frase= frase + \" \"+ token.lemma_\n",
    "                else:\n",
    "                    \n",
    "                    frase= frase + \" \"+ token.lemma_\n",
    "            elif token.dep_ in [\"ROOT\"] and token.pos_ in [\"VERB\"] and anterior==\"NUM\":\n",
    "                #palabras.append(frase+\" \"+token.lemma_)\n",
    "                palabras.append(token.lemma_)\n",
    "                frase=\"\"\n",
    "            elif token.dep_ in [\"ROOT\"] and token.pos_ in [\"VERB\"]:\n",
    "                if frase!=\"\":\n",
    "                    palabras.append(frase.split()[-1])\n",
    "                    if len(frase.split())>1:\n",
    "                        dir_sust[frase.split()[-1]]=','.join(frase.split()[0:-1])\n",
    "                    else:\n",
    "                        dir_sust[frase.split()[-1]]=\"NA\"\n",
    "                    palabras.append(token.lemma_)\n",
    "                    dir_sust[token.lemma_]=\"NA\"\n",
    "                else:\n",
    "                    palabras.append(token.lemma_)\n",
    "                    dir_sust[token.lemma_]=\"NA\"\n",
    "                frase=\"\"\n",
    "            else:\n",
    "                #print(frase)\n",
    "                if frase!=\"\":\n",
    "                    palabras.append(frase.split()[-1])\n",
    "                    if len(frase.split())>1:\n",
    "                        dir_sust[frase.split()[-1]]=','.join(frase.split()[0:-1])\n",
    "                    else:\n",
    "                        dir_sust[frase.split()[-1]]=\"NA\"\n",
    "                frase=\"\"\n",
    "        anterior=token.pos_\n",
    "    if frase!=\"\":\n",
    "        palabras.append(frase.split()[-1])\n",
    "        if len(frase.split())>1:\n",
    "            dir_sust[frase.split()[-1]]=','.join(frase.split()[0:-1])\n",
    "        else:\n",
    "            dir_sust[frase.split()[-1]]=\"NA\"\n",
    "    # poses.append(\"<F>\")\n",
    "    # tokens.append(\"</F>\")\n",
    "    # lemmas.append(\"</F>\")\n",
    "    # children.append(\"</F>\")\n",
    "    # verb_vincu.append(\"</F>\")\n",
    "    # deps.append(\"</F>\")\n",
    "    # print(\"tokens\",tokens)\n",
    "    # print(\"poses\",poses)\n",
    "    # print(\"lemmas\",lemmas)#\n",
    "    # print(\"children\",children)\n",
    "    # print(\"verbos_vinculantes\",verb_vincu)#\n",
    "    # print(\"deps\",deps)\n",
    "    return dir_sust,palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tags=[ 'acl',\n",
    " 'acomp',\n",
    " 'advcl',\n",
    " 'advmod',\n",
    " 'amod',\n",
    " 'appos',\n",
    " 'ccomp',\n",
    " 'complm',\n",
    " 'compound',\n",
    " 'conj',\n",
    " 'infmod',\n",
    " 'meta',\n",
    " 'neg',\n",
    " 'nmod',\n",
    " 'nn',\n",
    " 'npadvmod',\n",
    " 'nounmod',\n",
    " 'npmod',\n",
    " 'num',\n",
    " 'number',\n",
    " 'nummod',\n",
    " 'partmod',\n",
    " 'pcomp',\n",
    " 'poss',\n",
    " 'possessive',\n",
    " 'prep',\n",
    " 'quantmod',\n",
    " 'rcmod',\n",
    " 'relcl',\n",
    " 'xcomp',\n",
    " 'adc',\n",
    " 'avc',\n",
    " 'mnr',\n",
    " 'mo',\n",
    " 'ng',\n",
    " 'nmc'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\") # modelo de nlp\n",
    "\n",
    "#ut.load_vectors_in_lang(nlp,\"../OPENAI/data/glove.840B.300d.txt\") # carga de vectores en nlp.wv\n",
    "ut.load_vectors_in_lang(nlp,\"./data/numberbatch-en-17.04b.txt\") # carga de vectores en nlp.wv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista de listas para dataframe\n",
    "new_data = { 'distancias' : [], 'entropia_total' : [],'entropias' : [],\n",
    "            'mutinf' : [], 'mearts' : [], 'max_info' : [], 'sumas' : [],\n",
    "            'mutinf_t' : [], 'mearts_t' : [], 'max_info_t' : [], 'sumas_t' : [],\n",
    "            'entail':[],'contra':[],'neutral':[],'no_match':[],'rel_conceptuales':[],\n",
    "            'list_comp' : [], 'diferencias' :[], 'list_incomp':[], 'entropia_relaciones':[],\n",
    "            'list_M' : [], 'list_m' : [], 'list_T' : [], 'Jaro-Winkler_rit':[], 'KL_divergence':[],\n",
    "            'negT' : [], 'verbT' : [], 'negH' : [], 'verbH':[], 'overlap_ent':[],'clases' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar los conjuntos de sinonimos, hyperonimos e hyponimos\n",
    "diccionario_sinonimos=dict()\n",
    "diccionario_hiperonimos=dict()\n",
    "diccionario_hyponimos=dict()\n",
    "#diccionario_antonimos=dict()\n",
    "\n",
    "df_temp=pd.read_pickle(\"salida/nuevo4a/Synonyms.pickle\")\n",
    "for index,strings in df_temp.iterrows():\n",
    "    diccionario_sinonimos[strings['word']]=strings['Synonym']\n",
    "\n",
    "df_temp=pd.read_pickle(\"salida/nuevo4a/Hyperonyms.pickle\")\n",
    "for index,strings in df_temp.iterrows():\n",
    "    diccionario_hiperonimos[strings['word']]=strings['Hyperonym']\n",
    "\n",
    "df_temp=pd.read_pickle(\"salida/nuevo4a/Hyponyms.pickle\")\n",
    "for index,strings in df_temp.iterrows():\n",
    "    diccionario_hyponimos[strings['word']]=strings['Hyponym']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos=[\"A person in orange clothing rests above a metro entrance.\"]\n",
    "hipotesis= [\"Someone is standing near a metro station\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer,util\n",
    "# modelSB = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4859835207462311\n"
     ]
    }
   ],
   "source": [
    "# emb1 = modelSB.encode(\"station\")\n",
    "# emb2 = modelSB.encode(\"metro\")\n",
    "# #Get the cosine similarity score between sentences\n",
    "# cos_sim = util.cos_sim(emb1, emb2)\n",
    "# print(float(cos_sim[0][0]))\n",
    "# #agregar esta parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "A person in orange clothing rests above a metro entrance.\n",
      "Someone is standing near a metro station\n",
      "['person', 'entrance', 'clothing', 'orange', 'rest', 'metro']\n",
      "['station', 'metro', 'stand']\n",
      "person station\n",
      "person metro\n",
      "person stand\n",
      "entrance station\n",
      "entrance metro\n",
      "entrance stand\n",
      "clothing station\n",
      "clothing metro\n",
      "clothing stand\n",
      "orange metro\n",
      "orange stand\n",
      "rest stand\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "0\n",
      "Valores para entropia {0.0, 0.1, 0.5, 0.2, -0.1, 1.0}\n",
      "Probabilidades [0.5, 0.2222222222222222, 0.05555555555555555, 0.1111111111111111, 0.05555555555555555, 0.05555555555555555]\n",
      "           station     metro     stand\n",
      "person    0.038627  0.017240  0.053521\n",
      "entrance  0.198481  0.110864  0.083514\n",
      "clothing -0.008238 -0.026447 -0.031997\n",
      "orange    0.021178  0.112946 -0.059310\n",
      "rest     -0.012533 -0.031303  0.173322\n",
      "metro     0.504996  1.000000  0.040170\n",
      "proceso de obtención de generalidad\n",
      "           station     stand\n",
      "person    0.038627  0.053521\n",
      "entrance  0.198481  0.083514\n",
      "clothing -0.008238 -0.031997\n",
      "orange    0.021178 -0.059310\n",
      "rest     -0.012533  0.173322\n",
      "metro     0.504996  0.040170 Index(['station', 'stand'], dtype='object')\n",
      "columna a checar station\n",
      "acces station metro 0.50499636\n",
      "Proceso de conjuntos\n",
      "acces station entrance 0.1984811\n",
      "Proceso de conjuntos\n",
      "acces station person 0.038627442\n",
      "Proceso de conjuntos\n",
      "columna a checar stand\n",
      "acces stand rest 0.17332184\n",
      "Proceso de conjuntos\n",
      "acces stand entrance 0.083513685\n",
      "Proceso de conjuntos\n",
      "acces stand person 0.053521227\n",
      "Proceso de conjuntos\n",
      "proceso de obtención de contradiction\n",
      "           station     stand\n",
      "person    0.038627  0.053521\n",
      "entrance  0.198481  0.083514\n",
      "clothing -0.008238 -0.031997\n",
      "orange    0.021178 -0.059310\n",
      "rest     -0.012533  0.173322\n",
      "metro     0.504996  0.040170 Index(['station', 'stand'], dtype='object')\n",
      "columna a checar para contradicción station\n",
      "acces station metro 0.50499636\n",
      "acces station entrance 0.1984811\n",
      "acces station person 0.038627442\n",
      "columna a checar para contradicción stand\n",
      "acces stand rest 0.17332184\n",
      "acces stand entrance 0.083513685\n",
      "acces stand person 0.053521227\n",
      "proceso de obtención de especificidad y conceptuales\n",
      "           station     stand\n",
      "person    0.038627  0.053521\n",
      "entrance  0.198481  0.083514\n",
      "clothing -0.008238 -0.031997\n",
      "orange    0.021178 -0.059310\n",
      "rest     -0.012533  0.173322\n",
      "metro     0.504996  0.040170 Index(['station', 'stand'], dtype='object')\n",
      "columna a checar para especificidad station\n",
      "accesar a checar conceptuales station metro 0.50499636\n",
      "accesar a checar conceptuales station entrance 0.1984811\n",
      "accesar a checar conceptuales station person 0.038627442\n",
      "columna a checar para especificidad stand\n",
      "accesar a checar conceptuales stand rest 0.17332184\n",
      "stand - rest | manner_of /a/[/r/manner_of/,/c/en/stand/v/wn/contact/,/c/en/rest/v/wn/contact/]\n",
      "proceso de obtención de no relaciones\n",
      "           station\n",
      "person    0.038627\n",
      "entrance  0.198481\n",
      "clothing -0.008238\n",
      "orange    0.021178\n",
      "rest     -0.012533\n",
      "metro     0.504996 Index(['station'], dtype='object')\n",
      "rel [1 2 3]\n",
      "Valores para entropia {1, 2, 3}\n",
      "Probabilidades [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "entropia final 1.584962500721156\n",
      "Valores para entropia {1, 2, 3}\n",
      "Probabilidades [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "Valores para entropia {0.0, 0.2, 0.5}\n",
      "Probabilidades [0.6666666666666666, 0.16666666666666666, 0.16666666666666666]\n",
      "Valores para entropia {0.0, 0.1, 0.5, 0.2, -0.1, 1.0}\n",
      "Probabilidades [0.5, 0.2222222222222222, 0.05555555555555555, 0.1111111111111111, 0.05555555555555555, 0.05555555555555555]\n",
      "Valores para entropia {0.0, 0.1, 0.5, 0.2, -0.1, 1.0}\n",
      "Probabilidades [0.6666666666666666, 0.0, 0.16666666666666666, 0.16666666666666666, 0.0, 0.0]\n",
      "           station\n",
      "person    0.038627\n",
      "entrance  0.198481\n",
      "clothing -0.008238\n",
      "orange    0.021178\n",
      "rest     -0.012533\n",
      "metro     0.504996\n",
      "Tiempo que se llevo: 0.21  segundos\n"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "for i in range(len(textos)):\n",
    "#for i in range(4):\n",
    "    print(i)\n",
    "    print(textos[i])\n",
    "    r_t,t_clean_m=representacion_entidades(nlp,textos[i])\n",
    "    # #r_t,t_clean_m=representacion2(nlp,textos[i])\n",
    "    #r_t,t_clean_m=representacion(nlp,textos[i])\n",
    "    neg_t,negadat=negacion(nlp,textos[i])\n",
    "    new_data['negT'].append(neg_t)\n",
    "    new_data['verbT'].append(negadat)\n",
    "    # #print(list(r_t.keys()))\n",
    "    # for clave in r_t.keys():\n",
    "    #     print(\"texto\",clave,r_t[clave])\n",
    "    print(hipotesis[i])\n",
    "    r_h,h_clean_m = representacion_entidades(nlp,hipotesis[i])\n",
    "    # #r_h,h_clean_m = representacion2(nlp,hipotesis[i])\n",
    "    #r_h,h_clean_m = representacion(nlp,hipotesis[i])\n",
    "    neg_h,negadah=negacion(nlp,hipotesis[i])\n",
    "    new_data['negH'].append(neg_h)\n",
    "    new_data['verbH'].append(negadah)\n",
    "    # for clave in r_h.keys():\n",
    "    #     print(\"hipotesis\",clave,r_h[clave])\n",
    "    if len(set(h_clean_m))!=0 and len(set(t_clean_m))!=0:\n",
    "        new_data['overlap_ent'].append(len(set(t_clean_m).intersection(set(h_clean_m)))/len(set(h_clean_m)))\n",
    "    else:\n",
    "        new_data['overlap_ent'].append(0)\n",
    "    t_lem=list(set(ut.get_lemmas_(textos[i],nlp)))\n",
    "    h_lem=list(set(ut.get_lemmas_(hipotesis[i],nlp)))\n",
    "    t_vectors=ut.get_matrix_rep2(t_lem, nlp, normed=False)\n",
    "    h_vectors=ut.get_matrix_rep2(h_lem, nlp, normed=False)\n",
    "    t_vectors_n=ut.get_matrix_rep2(t_lem, nlp, normed=True)\n",
    "    h_vectors_n=ut.get_matrix_rep2(h_lem, nlp, normed=True)\n",
    "    \n",
    "    # print(t_vectors)\n",
    "    # print(h_vectors)\n",
    "    # print(t_clean_m,h_clean_m)\n",
    "    \n",
    "    # s1=t_clean_m.split()\n",
    "    # s2=h_clean_m.split()\n",
    "    for t in t_lem:\n",
    "        if t not in diccionario_sinonimos:\n",
    "            diccionario_sinonimos[t]=bag_of_synonyms(t)\n",
    "        if t not in diccionario_hiperonimos:\n",
    "            diccionario_hiperonimos[t]=bag_of_hyperonyms(t)\n",
    "        if t not in diccionario_hyponimos:\n",
    "            diccionario_hyponimos[t]=bag_of_hyponyms(t)\n",
    "        # if t not in diccionario_antonimos:\n",
    "        #     diccionario_antonimos[t]=bag_of_antonyms(t)\n",
    "    for t in h_lem:\n",
    "        if t not in diccionario_sinonimos:\n",
    "            diccionario_sinonimos[t]=bag_of_synonyms(t)\n",
    "        if t not in diccionario_hiperonimos:\n",
    "            diccionario_hiperonimos[t]=bag_of_hyperonyms(t)\n",
    "        if t not in diccionario_hyponimos:\n",
    "            diccionario_hyponimos[t]=bag_of_hyponyms(t)\n",
    "        # if t not in diccionario_antonimos:\n",
    "        #     diccionario_antonimos[t]=bag_of_antonyms(t)\n",
    "\n",
    "    s1=t_lem\n",
    "    s2=h_lem\n",
    "    \n",
    "    sinT=[]\n",
    "    antT=[]\n",
    "    HipT=[]\n",
    "    sinH=[]\n",
    "    antH=[]\n",
    "    HipH=[]\n",
    "    hipH=[]\n",
    "    \n",
    "    # # encontrar bolsa de sinonimos de cada token\n",
    "    for t in s1:\n",
    "        sinT.append(diccionario_sinonimos[t])\n",
    "        HipT.append(diccionario_hiperonimos[t])\n",
    "\n",
    "    for h in s2:\n",
    "        sinH.append(diccionario_sinonimos[h])\n",
    "        hipH.append(diccionario_hyponimos[h])\n",
    "\n",
    "    print(t_lem)\n",
    "    print(h_lem)\n",
    "    tp1=jaro_distance(t_lem, h_lem,sinT,sinH,HipT,hipH)\n",
    "    new_data['Jaro-Winkler_rit'].append(tp1)\n",
    "\n",
    "    # # Obtencion de matriz de alineamiento, matriz de move earth y mutual information\n",
    "    ma=np.dot(t_vectors_n,h_vectors_n.T)\n",
    "    #print(t_clean,h_clean)\n",
    "    #print(len(t_vectors_n),len(h_vectors_n),len(t_clean),len(h_clean))\n",
    "    m_earth,m_mi=wasserstein_mutual_inf(t_vectors_n,h_vectors_n,t_lem,h_lem)\n",
    "    ma=pd.DataFrame(ma,index=t_lem,columns=h_lem)\n",
    "    #print(ma)\n",
    "    new_data['max_info_t'].append(ma.max().sum()/(ma.shape[1]))#\n",
    "    new_data['sumas_t'].append(ma.sum().sum()/((ma.shape[1]*(ma.shape[0]))))#\n",
    "    new_data['mearts_t'].append(m_earth.min().sum()/(ma.shape[1]))# \n",
    "    new_data['mutinf_t'].append(m_mi.max().sum()/(ma.shape[1]))# \n",
    "    # # Calculamos la entropia inicial de la matriz de distancias coseno sobre tokens de T y H\n",
    "    distX = ma.round(1).values.flatten()\n",
    "    new_data['entropia_total'].append(entropia(distX)) \n",
    "\n",
    "    # ###### BORRADO DE COSAS QUE NO OCUPO, SOLO NOS QUEDAMOS CON INFORMACIÓN DE TIPOS DE PALABRA: NOUN, VERB, ADJ Y ADV\n",
    "    # # TAMBIÉN OMITIMOS EL VERBO BE DEBIDO A QUE POR LO REGULAR SE UTILIZA COMO AUXILIAR Y ES UN VERBO COPULATIVO\n",
    "    # # sirve para construir la llamada predicación nominal del sujeto de una oración: \n",
    "    # # #el sujeto se une con este verbo a un complemento obligatorio llamado atributo que por lo general determina \n",
    "    # # alguna propiedad, estado o equivalencia del mismo, por ejemplo: \"Este plato es bueno\". \"Juan está casado\".\n",
    "    c_compatibilidad=0\n",
    "    c_incompatibilidad=0\n",
    "    c_rel_concep=0\n",
    "    b_col=[0]\n",
    "\n",
    "    new_data['list_T'].append(ma.shape[0])\n",
    "    new_data['list_M'].append(ma.shape[1])\n",
    "    print(ma)\n",
    "    # val=ma.max().values\n",
    "    # print(\"valores maximos\",val.round(1))\n",
    "    # print(\"entropias de valores maximos\",entropia(val.round(1)))\n",
    "\n",
    "    #procesamiento de cosas que son la misma entidad\n",
    "    borrar=list(set(t_lem).intersection(set(h_lem)))\n",
    "    ma = ma.drop(borrar,axis=1)\n",
    "    m_earth = m_earth.drop(borrar,axis=1)\n",
    "    m_mi = m_mi.drop(borrar,axis=1)\n",
    "    b_col.extend(borrar)\n",
    "\n",
    "    #Como son palabras iguales entonces se agregan como uno que significa una realcion de entailment\n",
    "    #calculo de relaciones con entropia\n",
    "    rel_entropia=[]\n",
    "    for b_c in borrar:\n",
    "        rel_entropia.append(1)\n",
    "\n",
    "    # a = ma.idxmax().values\n",
    "    # b = ma.columns\n",
    "    top_k=3\n",
    "    # # #PARA REVISAR SI EXISTEN RELACIONES DE SIMILITUD SEMÁNTICA A TRAVÉS DEL USO DE CONCEPNET\n",
    "    print(\"proceso de obtención de generalidad\")\n",
    "    print(ma,ma.columns)\n",
    "    for c_c in ma.columns:\n",
    "        print(\"columna a checar\",c_c)\n",
    "        # filtrar el top 3 de los mejores similitud coseno para cada token de H vs tokens de T que sean mayores a 0\n",
    "        # una vez que encontremos quien se sale del ciclo\n",
    "        temp=ma[c_c].sort_values(ascending=False)\n",
    "        ranks=list(temp[:top_k].index)\n",
    "        valranks=list(temp[:top_k].values)\n",
    "        for r_i in range(len(ranks)):\n",
    "            borrar=[]\n",
    "            print(\"acces\",c_c,ranks[r_i],valranks[r_i])\n",
    "            if valranks[r_i]>0:\n",
    "                r_wt=str(ranks[r_i])\n",
    "                r_wh=str(c_c)\n",
    "                if(relacion_entailment(r_wt,r_wh)):\n",
    "                    borrar.append(r_wh)\n",
    "                    rel_entropia.append(1)\n",
    "                    c_compatibilidad+=1\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Proceso de conjuntos\")\n",
    "                    sin1=diccionario_sinonimos[r_wt]\n",
    "                    sin2=diccionario_sinonimos[r_wh]\n",
    "                    if len(sin1.intersection(sin2))>0:\n",
    "                        borrar.append(r_wh)\n",
    "                        c_compatibilidad+=1\n",
    "                        rel_entropia.append(1)\n",
    "                        break\n",
    "                    else:\n",
    "                        Hip1=set()\n",
    "                        for e in list(sin1):\n",
    "                            if e in diccionario_hiperonimos:\n",
    "                                Hip1=Hip1.union(diccionario_hiperonimos[e])\n",
    "                            else:\n",
    "                                b_H=bag_of_hyperonyms(e)\n",
    "                                Hip1=Hip1.union(b_H)\n",
    "                                diccionario_hiperonimos[e]=b_H\n",
    "                        if len(Hip1.intersection(sin2))>0:\n",
    "                            borrar.append(r_wh)\n",
    "                            c_compatibilidad+=1\n",
    "                            rel_entropia.append(1)\n",
    "                            break\n",
    "                        else:\n",
    "                            hip2=set()\n",
    "                            for e in list(sin2):\n",
    "                                if e in diccionario_hyponimos:\n",
    "                                    hip2=hip2.union(diccionario_hyponimos[e])\n",
    "                                else:\n",
    "                                    b_H=bag_of_hyponyms(e)\n",
    "                                    hip2=hip2.union(b_H)\n",
    "                                    diccionario_hyponimos[e]=b_H                                \n",
    "                            if len(sin1.intersection(hip2))>0:   \n",
    "                                borrar.append(r_wh)\n",
    "                                c_compatibilidad+=1\n",
    "                                rel_entropia.append(1)\n",
    "                                break\n",
    "        ma = ma.drop(borrar,axis=1)\n",
    "        m_earth = m_earth.drop(borrar,axis=1)\n",
    "        m_mi = m_mi.drop(borrar,axis=1)\n",
    "        n_columns = ma.shape[1]\n",
    "        b_col.extend(borrar)\n",
    "\n",
    "    # proceso para saber si hay contradiction en los que faltan\n",
    "    print(\"proceso de obtención de contradiction\")\n",
    "    print(ma,ma.columns)\n",
    "    for c_c in ma.columns:\n",
    "        print(\"columna a checar para contradicción\",c_c)\n",
    "        # filtrar el top 3 de los mejores similitud coseno para cada token de H vs tokens de T que sean mayores a 0\n",
    "        # una vez que encontremos quien se sale del ciclo\n",
    "        temp=ma[c_c].sort_values(ascending=False)\n",
    "        ranks=list(temp[:top_k].index)\n",
    "        valranks=list(temp[:top_k].values)\n",
    "        for r_i in range(len(ranks)):\n",
    "            borrar=[]\n",
    "            print(\"acces\",c_c,ranks[r_i],valranks[r_i])\n",
    "            if valranks[r_i]>0:\n",
    "                r_wt=str(ranks[r_i])\n",
    "                r_wh=str(c_c)\n",
    "                if(relacion_noentailment(r_wt,r_wh)):\n",
    "                    c_incompatibilidad+=1\n",
    "                    rel_entropia.append(0)\n",
    "                    borrar.append(r_wh)\n",
    "                    break\n",
    "                #else:\n",
    "                    # sin1=diccionario_sinonimos[r_wt]\n",
    "                    # sin2=diccionario_sinonimos[r_wh]\n",
    "                    # Hip1=set()\n",
    "                    # for e in list(sin1):\n",
    "                    #     if e in diccionario_hiperonimos:\n",
    "                    #         Hip1=Hip1.union(diccionario_hiperonimos[e])\n",
    "                    #     else:\n",
    "                    #         b_H=bag_of_hyperonyms(e)\n",
    "                    #         Hip1=Hip1.union(b_H)\n",
    "                    #         diccionario_hiperonimos[e]=b_H\n",
    "                    # Hip2=set()\n",
    "                    # for e in list(sin2):\n",
    "                    #     if e in diccionario_hiperonimos:\n",
    "                    #         Hip2=Hip2.union(diccionario_hiperonimos[e])\n",
    "                    #     else:\n",
    "                    #         b_H=bag_of_hyperonyms(e)\n",
    "                    #         Hip2=Hip2.union(b_H)\n",
    "                    #         diccionario_hiperonimos[e]=b_H\n",
    "                    # Hip1=diccionario_hiperonimos[r_wt]\n",
    "                    # Hip2=diccionario_hiperonimos[r_wh]\n",
    "                    # if len(Hip1.intersection(Hip2))>0:\n",
    "                    #     c_incompatibilidad+=1\n",
    "                    #     rel_entropia.append(0)\n",
    "                    #     borrar.append(r_wh)\n",
    "                    #     break\n",
    "\n",
    "        ma = ma.drop(borrar,axis=1)\n",
    "        m_earth = m_earth.drop(borrar,axis=1)\n",
    "        m_mi = m_mi.drop(borrar,axis=1)\n",
    "        n_columns = ma.shape[1]\n",
    "        b_col.extend(borrar)\n",
    "\n",
    "    #proceso para checar las relaciones conceptuales que existen\n",
    "    print(\"proceso de obtención de especificidad y conceptuales\")\n",
    "    print(ma,ma.columns)\n",
    "    for c_c in ma.columns:\n",
    "        print(\"columna a checar para especificidad\",c_c)\n",
    "        # filtrar el top 3 de los mejores similitud coseno para cada token de H vs tokens de T que sean mayores a 0\n",
    "        # una vez que encontremos quien se sale del ciclo\n",
    "        temp=ma[c_c].sort_values(ascending=False)\n",
    "        ranks=list(temp[:top_k].index)\n",
    "        valranks=list(temp[:top_k].values)\n",
    "        for r_i in range(len(ranks)):\n",
    "            borrar=[]\n",
    "            print(\"accesar a checar conceptuales\",c_c,ranks[r_i],valranks[r_i])\n",
    "            if valranks[r_i]>0:\n",
    "                r_wt=str(ranks[r_i])\n",
    "                r_wh=str(c_c)                \n",
    "                if (relacion_conceptual(r_wt,r_wh)):\n",
    "                    rel_entropia.append(2)\n",
    "                    c_rel_concep+=1\n",
    "                    borrar.append(r_wh)\n",
    "                    break\n",
    "        ma = ma.drop(borrar,axis=1)\n",
    "        m_earth = m_earth.drop(borrar,axis=1)\n",
    "        m_mi = m_mi.drop(borrar,axis=1)\n",
    "        n_columns = ma.shape[1]\n",
    "        b_col.extend(borrar)\n",
    "    b_index=[0]\n",
    "    #proceso para checar las no relaciones que existen\n",
    "    print(\"proceso de obtención de no relaciones\")\n",
    "    print(ma,ma.columns)\n",
    "    for c_c in ma.columns:\n",
    "        rel_entropia.append(3)\n",
    "\n",
    "    print(\"rel\",np.array(rel_entropia).round(1))\n",
    "    print(\"entropia final\",entropia(np.array(rel_entropia).round(1)))\n",
    "\n",
    "    new_data['entail'].append(rel_entropia.count(1)/len(rel_entropia))\n",
    "    new_data['contra'].append(rel_entropia.count(0)/len(rel_entropia))\n",
    "    new_data['neutral'].append(rel_entropia.count(2)/len(rel_entropia))\n",
    "    new_data['no_match'].append(rel_entropia.count(3)/len(rel_entropia))\n",
    "    new_data['entropia_relaciones'].append(entropia(np.array(rel_entropia).round(1)))\n",
    "    # #   ALMACENAMIENTO DE TODA LA INFORMACIÓN PROCESADA DE CARACTERÍSTICAS\n",
    "    m_distancia = obtener_distancia(t_vectors,h_vectors,t_lem,h_lem,b_col,b_index)\n",
    "    m_earth=m_earth*m_distancia\n",
    "    if ma.shape[1]==0:\n",
    "        new_data['entropias'].append(0)\n",
    "        new_data['KL_divergence'].append(0)\n",
    "        new_data['max_info'].append(0)\n",
    "        new_data['sumas'].append(0)\n",
    "        new_data['mearts'].append(0)\n",
    "        new_data['mutinf'].append(0)\n",
    "        new_data['diferencias'].append(0)\n",
    "        new_data['distancias'].append(0)\n",
    "    else:\n",
    "        distY = ma.round(1).values.flatten()\n",
    "        new_data['entropias'].append(entropia(distY))\n",
    "        new_data['KL_divergence'].append(kullback_leibler(distX,distY))\n",
    "        new_data['max_info'].append(ma.max().sum()/(ma.shape[1]))#\n",
    "        new_data['sumas'].append(ma.sum().sum()/((ma.shape[1]*(ma.shape[0]))))#\n",
    "        new_data['mearts'].append(m_earth.min().sum()/(ma.shape[1]))# \n",
    "        new_data['mutinf'].append(m_mi.max().sum()/(ma.shape[1]))# \n",
    "        new_data['diferencias'].append(len(ma.columns)/len(ma.index))\n",
    "        new_data['distancias'].append(m_distancia.min().sum()/(ma.shape[1])) #cambie de maximas a sumas\n",
    "\n",
    "    new_data['list_comp'].append(c_compatibilidad)\n",
    "    new_data['list_incomp'].append(c_incompatibilidad)\n",
    "    new_data['rel_conceptuales'].append(c_rel_concep)\n",
    "    new_data['list_m'].append(ma.shape[1])\n",
    "    new_data['clases'].append(1)\n",
    "    print(ma)\n",
    "\n",
    "fin = time.time()\n",
    "print(\"Tiempo que se llevo:\",round(fin-inicio,2),\" segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# verificar la función de creación de entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representacion_entidades_F(nlp,texto):\n",
    "    dir_sust=dict()\n",
    "    palabras=[]\n",
    "    b=1.0\n",
    "    if (type(texto)==type(b) or texto==\"\" or texto==\"n/a\" or texto==\"nan\"):\n",
    "        return dir_sust,palabras\n",
    "    doc =nlp(texto.lower())\n",
    "    for token in doc:\n",
    "        if token.dep_ in tags:\n",
    "            print(token.text, token.lemma_, token.pos_,token.dep_,token.head.text,token.head.lemma_, token.head.pos_,\n",
    "                [child for child in token.children])\n",
    "            #sustantivos.append(token.head.lemma_)\n",
    "            if token.head.lemma_ in dir_sust:\n",
    "                if dir_sust[token.head.lemma_]==\"NA\":\n",
    "                    dir_sust[token.head.lemma_]=token.lemma_\n",
    "                    if token.head not in palabras:\n",
    "                        palabras.append(token.head)\n",
    "                else:\n",
    "                    dir_sust[token.head.lemma_]=dir_sust[token.head.lemma_]+\",\"+token.lemma_\n",
    "                    if token.head not in palabras:\n",
    "                        palabras.append(token.head)\n",
    "            else:\n",
    "                dir_sust[token.head.lemma_]=token.lemma_\n",
    "                if token.head not in palabras:\n",
    "                    palabras.append(token.head)\n",
    "        elif token.pos_ in [\"NOUN\",\"PROPN\",\"PRON\"]:\n",
    "            #print(token.text,token.lemma_, token.pos_,token.dep_)\n",
    "            #sustantivos.append(token.lemma_)\n",
    "            if token.lemma_ not in dir_sust:\n",
    "                dir_sust[token.lemma_]=\"NA\"\n",
    "                if token not in palabras:\n",
    "                    palabras.append(token)\n",
    "        elif token.pos_ in [\"VERB\"]:\n",
    "            #print(token.text, token.lemma_,token.pos_,token.dep_)\n",
    "            #sustantivos.append(token.lemma_)\n",
    "            if token.lemma_ not in dir_sust:\n",
    "                dir_sust[token.lemma_]=\"NA\"\n",
    "                if token not in palabras:\n",
    "                    palabras.append(token)\n",
    "        else:\n",
    "            print(token.text,token.pos_)\n",
    "    return dir_sust,palabras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a DET\n",
      "in in ADP prep person person NOUN [clothing]\n",
      "orange orange ADJ compound clothing clothing NOUN []\n",
      "above above ADP prep rests rest VERB [entrance]\n",
      "a DET\n",
      "metro metro NOUN compound entrance entrance NOUN []\n",
      ". PUNCT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'person': 'in', 'clothing': 'orange', 'rest': 'above', 'entrance': 'metro'},\n",
       " [person, clothing, rests, entrance])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representacion_entidades_F(nlp,\"A person in orange clothing rests above a metro entrance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is AUX\n",
      "near near ADP prep standing stand VERB [station]\n",
      "a DET\n",
      "metro metro NOUN compound station station NOUN []\n",
      ". PUNCT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'someone': 'NA', 'stand': 'near', 'station': 'metro'},\n",
       " [someone, standing, station])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representacion_entidades_F(nlp,\"Someone is standing near a metro station.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relacion_entailment(\"rest\",\"stand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relacion_conceptual(\"talk\",\"dinner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_resultados \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_resultados\n",
      "File \u001b[0;32m~/anaconda3/envs/rit/lib/python3.9/site-packages/pandas/core/frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    729\u001b[0m     )\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/anaconda3/envs/rit/lib/python3.9/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rit/lib/python3.9/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/anaconda3/envs/rit/lib/python3.9/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "df_resultados = pd.DataFrame(new_data)\n",
    "df_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['distancias', 'entropia_total', 'entropias', 'mutinf', 'mearts',\n",
       "       'max_info', 'sumas', 'mutinf_t', 'mearts_t', 'max_info_t', 'sumas_t',\n",
       "       'entail', 'contra', 'neutral', 'no_match', 'rel_conceptuales',\n",
       "       'list_comp', 'diferencias', 'list_incomp', 'entropia_relaciones',\n",
       "       'list_M', 'list_m', 'list_T', 'Jaro-Winkler_rit', 'KL_divergence',\n",
       "       'negT', 'verbT', 'negH', 'verbH', 'overlap_ent', 'clases'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'entail'}, xlabel='clases'>,\n",
       "        <Axes: title={'center': 'contra'}, xlabel='clases'>],\n",
       "       [<Axes: title={'center': 'neutral'}, xlabel='clases'>,\n",
       "        <Axes: title={'center': 'no_match'}, xlabel='clases'>],\n",
       "       [<Axes: title={'center': 'rel_conceptuales'}, xlabel='clases'>,\n",
       "        <Axes: >]], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_resultados.boxplot(by=\"clases\",column=['entail', 'contra', 'neutral', 'no_match', 'rel_conceptuales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# proceos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>table</th>\n",
       "      <th>cluband</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>-0.008238</td>\n",
       "      <td>0.022620</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orange</th>\n",
       "      <td>0.021178</td>\n",
       "      <td>-0.083560</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metro</th>\n",
       "      <td>0.504996</td>\n",
       "      <td>-0.058719</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <td>0.038627</td>\n",
       "      <td>0.051114</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entrance</th>\n",
       "      <td>0.198481</td>\n",
       "      <td>0.061389</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest</th>\n",
       "      <td>-0.012533</td>\n",
       "      <td>0.090798</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           station     table  cluband\n",
       "clothing -0.008238  0.022620      0.0\n",
       "orange    0.021178 -0.083560      0.0\n",
       "metro     0.504996 -0.058719      0.0\n",
       "person    0.038627  0.051114      0.0\n",
       "entrance  0.198481  0.061389      0.0\n",
       "rest     -0.012533  0.090798      0.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station [0.50499636 0.1984811  0.03862744]\n",
      "station metro 0.50499636\n",
      "station entrance 0.1984811\n",
      "station person 0.038627442\n"
     ]
    }
   ],
   "source": [
    "#temp=ma.copy()\n",
    "for c in ma.columns:\n",
    "    temp=ma[c][1:].sort_values(ascending=False)\n",
    "    print(c,temp[:3].values)\n",
    "    ranks=list(temp[:3].index)\n",
    "    valranks=list(temp[:3].values)\n",
    "    for r_i in range(len(ranks)):\n",
    "        print(c,ranks[r_i],valranks[r_i])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'metro rest clothing'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(ma.idxmax().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'station table cluband'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(ma.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase1=\"Some squirrels are mammals.\"\n",
    "frase2=\"No squirrels are mammals.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7555228471755981\n"
     ]
    }
   ],
   "source": [
    "emb1 = modelSB.encode(frase1)\n",
    "emb2 = modelSB.encode(frase2)\n",
    "#Get the cosine similarity score between sentences\n",
    "cos_sim = util.cos_sim(emb1, emb2)\n",
    "print(float(cos_sim[0][0]))\n",
    "#agregar esta parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase1=\"The cat sat on the mat\"\n",
    "frase2=\"The animal sat on the mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7351410984992981\n"
     ]
    }
   ],
   "source": [
    "emb1 = modelSB.encode(frase1)\n",
    "emb2 = modelSB.encode(frase2)\n",
    "#Get the cosine similarity score between sentences\n",
    "cos_sim = util.cos_sim(emb1, emb2)\n",
    "print(float(cos_sim[0][0]))\n",
    "#agregar esta parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9700795397036415\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(frase1)\n",
    "doc2 = nlp(frase2)\n",
    "print(doc1.similarity(doc2))\n",
    "#\n",
    "#    bien_me.append(getWDM(st,sh))\n",
    "#elif st!=\"\" and sh==\"\":\n",
    "#    similitud_faltantes.append(1)\n",
    "#    bien_me.append(0)\n",
    "#else:\n",
    "#    similitud_faltantes.append(0)\n",
    "#    bien_me.append(0)\n",
    "# 0.8528367657386307"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>table</th>\n",
       "      <th>cluband</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>-0.008238</td>\n",
       "      <td>0.022620</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orange</th>\n",
       "      <td>0.021178</td>\n",
       "      <td>-0.083560</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metro</th>\n",
       "      <td>0.504996</td>\n",
       "      <td>-0.058719</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <td>0.038627</td>\n",
       "      <td>0.051114</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entrance</th>\n",
       "      <td>0.198481</td>\n",
       "      <td>0.061389</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest</th>\n",
       "      <td>-0.012533</td>\n",
       "      <td>0.090798</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           station     table  cluband\n",
       "clothing -0.008238  0.022620      0.0\n",
       "orange    0.021178 -0.083560      0.0\n",
       "metro     0.504996 -0.058719      0.0\n",
       "person    0.038627  0.051114      0.0\n",
       "entrance  0.198481  0.061389      0.0\n",
       "rest     -0.012533  0.090798      0.0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>table</th>\n",
       "      <th>cluband</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>3.549515</td>\n",
       "      <td>3.586446</td>\n",
       "      <td>8.135714e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orange</th>\n",
       "      <td>3.628371</td>\n",
       "      <td>3.660681</td>\n",
       "      <td>7.656098e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metro</th>\n",
       "      <td>3.694917</td>\n",
       "      <td>3.736469</td>\n",
       "      <td>7.345236e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <td>3.803109</td>\n",
       "      <td>3.830798</td>\n",
       "      <td>6.474821e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entrance</th>\n",
       "      <td>3.740643</td>\n",
       "      <td>3.796058</td>\n",
       "      <td>6.936673e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest</th>\n",
       "      <td>3.770016</td>\n",
       "      <td>3.797705</td>\n",
       "      <td>6.714629e-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           station     table       cluband\n",
       "clothing  3.549515  3.586446  8.135714e-13\n",
       "orange    3.628371  3.660681  7.656098e-13\n",
       "metro     3.694917  3.736469  7.345236e-13\n",
       "person    3.803109  3.830798  6.474821e-13\n",
       "entrance  3.740643  3.796058  6.936673e-13\n",
       "rest      3.770016  3.797705  6.714629e-13"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station      person\n",
       "table        person\n",
       "cluband    clothing\n",
       "dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_mi.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# move earts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>table</th>\n",
       "      <th>cluband</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.007409</td>\n",
       "      <td>0.008844</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orange</th>\n",
       "      <td>0.006650</td>\n",
       "      <td>0.011922</td>\n",
       "      <td>0.045438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metro</th>\n",
       "      <td>0.006159</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.045585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <td>0.007354</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>0.045378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entrance</th>\n",
       "      <td>0.006094</td>\n",
       "      <td>0.005811</td>\n",
       "      <td>0.045739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest</th>\n",
       "      <td>0.005140</td>\n",
       "      <td>0.005931</td>\n",
       "      <td>0.045659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           station     table   cluband\n",
       "clothing  0.007409  0.008844  0.043478\n",
       "orange    0.006650  0.011922  0.045438\n",
       "metro     0.006159  0.005172  0.045585\n",
       "person    0.007354  0.011560  0.045378\n",
       "entrance  0.006094  0.005811  0.045739\n",
       "rest      0.005140  0.005931  0.045659"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station        rest\n",
       "table         metro\n",
       "cluband    clothing\n",
       "dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_earth.idxmin()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
