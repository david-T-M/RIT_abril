{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# obtener sinonimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Synonym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sale</td>\n",
       "      <td>{cut_rate_sale, sales_event, sales_agreement, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make</td>\n",
       "      <td>{do, shuffle, puddle, get, spend_penny, urinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pay</td>\n",
       "      <td>{pay_off, action, ante_up, yield, pay, remuner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yukos</td>\n",
       "      <td>{yukos}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>{xxvii, 27, twenty_seven}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72755</th>\n",
       "      <td>siewi</td>\n",
       "      <td>{siewi}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72756</th>\n",
       "      <td>dislikable</td>\n",
       "      <td>{dislikable}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72757</th>\n",
       "      <td>gispy</td>\n",
       "      <td>{gispy}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72758</th>\n",
       "      <td>buitl</td>\n",
       "      <td>{buitl}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72759</th>\n",
       "      <td>holysmoke</td>\n",
       "      <td>{holysmoke}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72760 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word                                            Synonym\n",
       "0            sale  {cut_rate_sale, sales_event, sales_agreement, ...\n",
       "1            make  {do, shuffle, puddle, get, spend_penny, urinat...\n",
       "2             pay  {pay_off, action, ante_up, yield, pay, remuner...\n",
       "3           yukos                                            {yukos}\n",
       "4              27                          {xxvii, 27, twenty_seven}\n",
       "...           ...                                                ...\n",
       "72755       siewi                                            {siewi}\n",
       "72756  dislikable                                       {dislikable}\n",
       "72757       gispy                                            {gispy}\n",
       "72758       buitl                                            {buitl}\n",
       "72759   holysmoke                                        {holysmoke}\n",
       "\n",
       "[72760 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sinonimos=pd.read_pickle(\"salida/nuevo4a/Synonyms.pickle\")\n",
    "df_sinonimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,strings in df_sinonimos.iterrows():\n",
    "    synonyms[strings['word']]=strings['Synonym']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72760"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(8):\n",
    "#     if i==0:\n",
    "#         df_syn = pd.read_pickle('salida/nuevo4a/RTE3/DEV_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "#     else:\n",
    "#         try:\n",
    "#             temp = pd.read_pickle('salida/nuevo4a/RTE3/DEV_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "#             df_syn=pd.concat([df_syn,temp])\n",
    "#         except:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(8):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/RTE3/TEST_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(8):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/GHS/GHS_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     if i==0:\n",
    "#         df_syn = pd.read_pickle('salida/nuevo4a/SICK/DEV_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "#     else:\n",
    "#         try:\n",
    "#             temp = pd.read_pickle('salida/nuevo4a/SICK/DEV_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "#             df_syn=pd.concat([df_syn,temp])\n",
    "#         except:\n",
    "#             print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(45):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/SICK/TRAIN_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/SICK/TEST_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     if i==0:\n",
    "#         df_syn = pd.read_pickle('salida/nuevo4a/SNLI/DEV/DEV_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "#     else:\n",
    "#         try:\n",
    "#             temp = pd.read_pickle('salida/nuevo4a/SNLI/DEV/DEV_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "#             df_syn=pd.concat([df_syn,temp])\n",
    "#         except:\n",
    "#             print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/SNLI/TEST/TEST_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(55):\n",
    "    if i==0:\n",
    "        df_syn = pd.read_pickle('salida/nuevo4a/SNLI/TRAIN10000/TRAIN_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "    else:\n",
    "        try:\n",
    "            temp = pd.read_pickle('salida/nuevo4a/SNLI/TRAIN10000/TRAIN_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "            df_syn=pd.concat([df_syn,temp])\n",
    "        except:\n",
    "            print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1):\n",
    "#     if i==0:\n",
    "#         df_syn = pd.read_pickle('salida/nuevo4a/RTEGLUE/TRAIN_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "#     else:\n",
    "#         try:\n",
    "#             temp = pd.read_pickle('salida/nuevo4a/RTEGLUE/TRAIN_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "#             df_syn=pd.concat([df_syn,temp])\n",
    "#         except:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/RTEGLUE/DEV_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_syn = pd.read_pickle('salida/nuevo4a/MultiNLI/DIAG/diagnostic-full.csv_Synonym.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_syn = pd.read_pickle('salida/nuevo4a/MultiNLI/DEVM/DEV_1.csv_Synonym.pickle')\n",
    "# temp = pd.read_pickle('salida/nuevo4a/MultiNLI/DEVMM/DEV_1.csv_Synonym.pickle')\n",
    "# df_syn=pd.concat([df_syn,temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(40):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/MultiNLI/TRAIN/TRAIN_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Synonym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sale</td>\n",
       "      <td>{sale, sales_event, sales_agreement, cut_rate_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make</td>\n",
       "      <td>{do, shuffle, puddle, get, urinate, pee_pee, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pay</td>\n",
       "      <td>{pay_off, action, ante_up, yield, pay, remuner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yukos</td>\n",
       "      <td>{yukos}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>{xxvii, 27, twenty_seven}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128032</th>\n",
       "      <td>rockclimb</td>\n",
       "      <td>{rockclimb}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128033</th>\n",
       "      <td>rockclimber</td>\n",
       "      <td>{rockclimber}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128034</th>\n",
       "      <td>spiderwoman</td>\n",
       "      <td>{spiderwoman}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128035</th>\n",
       "      <td>prformance</td>\n",
       "      <td>{prformance}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128036</th>\n",
       "      <td>chilldren</td>\n",
       "      <td>{chilldren}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128037 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word                                            Synonym\n",
       "0               sale  {sale, sales_event, sales_agreement, cut_rate_...\n",
       "1               make  {do, shuffle, puddle, get, urinate, pee_pee, s...\n",
       "2                pay  {pay_off, action, ante_up, yield, pay, remuner...\n",
       "3              yukos                                            {yukos}\n",
       "4                 27                          {xxvii, 27, twenty_seven}\n",
       "...              ...                                                ...\n",
       "1128032    rockclimb                                        {rockclimb}\n",
       "1128033  rockclimber                                      {rockclimber}\n",
       "1128034  spiderwoman                                      {spiderwoman}\n",
       "1128035   prformance                                       {prformance}\n",
       "1128036    chilldren                                        {chilldren}\n",
       "\n",
       "[1128037 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_syn = df_syn.reset_index(drop=True)\n",
    "df_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65183"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_syn['word'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn=df_syn.drop_duplicates('word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,strings in df_syn.iterrows():\n",
    "    synonyms[strings['word']]=strings['Synonym']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73482"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[key, synonyms[key]] for key in synonyms.keys()], columns=['word', 'Synonym'])\n",
    "df.to_pickle(\"salida/nuevo4a/Synonyms.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de pickle con hiperonimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperonimos=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Hyperonym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sale</td>\n",
       "      <td>{exchange, selling, merchantability, occasion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make</td>\n",
       "      <td>{tidy, look, become, constitute, assemble, amo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pay</td>\n",
       "      <td>{person_now_paid, payment, make, digest, be, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yukos</td>\n",
       "      <td>{company, yuko}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98490</th>\n",
       "      <td>dislikable</td>\n",
       "      <td>{dislike}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98491</th>\n",
       "      <td>gispy</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98492</th>\n",
       "      <td>unremittingly</td>\n",
       "      <td>{unremitting}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98493</th>\n",
       "      <td>buitl</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98494</th>\n",
       "      <td>holysmoke</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98495 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word                                          Hyperonym\n",
       "0               sale  {exchange, selling, merchantability, occasion,...\n",
       "1               make  {tidy, look, become, constitute, assemble, amo...\n",
       "2                pay  {person_now_paid, payment, make, digest, be, r...\n",
       "3              yukos                                    {company, yuko}\n",
       "4                 27                                                 {}\n",
       "...              ...                                                ...\n",
       "98490     dislikable                                          {dislike}\n",
       "98491          gispy                                                 {}\n",
       "98492  unremittingly                                      {unremitting}\n",
       "98493          buitl                                                 {}\n",
       "98494      holysmoke                                                 {}\n",
       "\n",
       "[98495 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hyp=pd.read_pickle(\"salida/nuevo4a/Hyperonyms.pickle\")\n",
    "df_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,strings in df_hyp.iterrows():\n",
    "    hyperonimos[strings['word']]=strings['Hyperonym']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98495"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hyperonimos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(8):\n",
    "#     if i==0:\n",
    "#         df_syn = pd.read_pickle('salida/nuevo4a/RTE3/DEV_'+str(i+1)+'.csv_Hyperonym.pickle')\n",
    "#     else:\n",
    "#         try:\n",
    "#             temp = pd.read_pickle('salida/nuevo4a/RTE3/DEV_'+str(i+1)+'.csv_Hyperonym.pickle')\n",
    "#             df_syn=pd.concat([df_syn,temp])\n",
    "#         except:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(8):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/RTE3/TEST_'+str(i+1)+'.csv_Hyperonym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(8):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/GHS/GHS_'+str(i+1)+'.csv_Hyperonym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     if i==0:\n",
    "#         df_syn = pd.read_pickle('salida/nuevo4a/SICK/DEV_'+str(i+1)+'.csv_Hyperonym.pickle')\n",
    "#     else:\n",
    "#         try:\n",
    "#             temp = pd.read_pickle('salida/nuevo4a/SICK/DEV_'+str(i+1)+'.csv_Hyperonym.pickle')\n",
    "#             df_syn=pd.concat([df_syn,temp])\n",
    "#         except:\n",
    "#             print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(45):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/SICK/TRAIN_'+str(i+1)+'.csv_Hyperonym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/SICK/TEST_'+str(i+1)+'.csv_Hyperonym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     if i==0:\n",
    "#         df_syn = pd.read_pickle('salida/nuevo4a/SNLI/DEV/DEV_'+str(i+1)+'.csv_Hyperonym.pickle')\n",
    "#     else:\n",
    "#         try:\n",
    "#             temp = pd.read_pickle('salida/nuevo4a/SNLI/DEV/DEV_'+str(i+1)+'.csv_Hyperonym.pickle')\n",
    "#             df_syn=pd.concat([df_syn,temp])\n",
    "#         except:\n",
    "#             print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/SNLI/TEST/TEST_'+str(i+1)+'.csv_Hyperonym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(55):\n",
    "    if i==0:\n",
    "        df_syn = pd.read_pickle('salida/nuevo4a/SNLI/TRAIN10000/TRAIN_'+str(i+1)+'.csv_Hyperonym.pickle')\n",
    "    else:\n",
    "        try:\n",
    "            temp = pd.read_pickle('salida/nuevo4a/SNLI/TRAIN10000/TRAIN_'+str(i+1)+'.csv_Hyperonym.pickle')\n",
    "            df_syn=pd.concat([df_syn,temp])\n",
    "        except:\n",
    "            print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1):\n",
    "#     if i==0:\n",
    "#         df_syn = pd.read_pickle('salida/nuevo4a/RTEGLUE/TRAIN_'+str(i+1)+'.csv_Hyperonym.pickle')\n",
    "#     else:\n",
    "#         try:\n",
    "#             temp = pd.read_pickle('salida/nuevo4a/RTEGLUE/TRAIN_'+str(i+1)+'.csv_Hyperonym.pickle')\n",
    "#             df_syn=pd.concat([df_syn,temp])\n",
    "#         except:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/RTEGLUE/DEV_'+str(i+1)+'.csv_Hyperonym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_syn = pd.read_pickle('salida/nuevo4a/MultiNLI/DIAG/diagnostic-full.csv_Hyperonym.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_syn = pd.read_pickle('salida/nuevo4a/MultiNLI/DEVM/DEV_1.csv_Hyperonym.pickle')\n",
    "# temp = pd.read_pickle('salida/nuevo4a/MultiNLI/DEVMM/DEV_1.csv_Hyperonym.pickle')\n",
    "# df_syn=pd.concat([df_syn,temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(40):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/MultiNLI/TRAIN/TRAIN_'+str(i+1)+'.csv_Hyperonym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Hyperonym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sale</td>\n",
       "      <td>{exchange, selling, merchantability, occasion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make</td>\n",
       "      <td>{tidy, look, become, constitute, amount, see, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pay</td>\n",
       "      <td>{person_now_paid, payment, make, digest, be, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yukos</td>\n",
       "      <td>{company, yuko}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968343</th>\n",
       "      <td>research_octane_number</td>\n",
       "      <td>{octane_number, octane_rating}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968344</th>\n",
       "      <td>daffo</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968345</th>\n",
       "      <td>bokkos</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968346</th>\n",
       "      <td>prformance</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968347</th>\n",
       "      <td>chilldren</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1968348 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           word  \\\n",
       "0                          sale   \n",
       "1                          make   \n",
       "2                           pay   \n",
       "3                         yukos   \n",
       "4                            27   \n",
       "...                         ...   \n",
       "1968343  research_octane_number   \n",
       "1968344                   daffo   \n",
       "1968345                  bokkos   \n",
       "1968346              prformance   \n",
       "1968347               chilldren   \n",
       "\n",
       "                                                 Hyperonym  \n",
       "0        {exchange, selling, merchantability, occasion,...  \n",
       "1        {tidy, look, become, constitute, amount, see, ...  \n",
       "2        {person_now_paid, payment, make, digest, be, r...  \n",
       "3                                          {company, yuko}  \n",
       "4                                                       {}  \n",
       "...                                                    ...  \n",
       "1968343                     {octane_number, octane_rating}  \n",
       "1968344                                                 {}  \n",
       "1968345                                                 {}  \n",
       "1968346                                                 {}  \n",
       "1968347                                                 {}  \n",
       "\n",
       "[1968348 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_syn = df_syn.reset_index(drop=True)\n",
    "df_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn=df_syn.drop_duplicates('word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,strings in df_syn.iterrows():\n",
    "    hyperonimos[strings['word']]=strings['Hyperonym']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99242"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hyperonimos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[key, hyperonimos[key]] for key in hyperonimos.keys()], columns=['word', 'Hyperonym'])\n",
    "df.to_pickle(\"salida/nuevo4a/Hyperonyms.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyponyms=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Hyponym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sale</td>\n",
       "      <td>{realization, closeout, saleyard, presale, sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make</td>\n",
       "      <td>{makeless, makest, bring_about, overmake, make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pay</td>\n",
       "      <td>{ypaid, paypig, payeth, pay_cash, paythrough, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yukos</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99475</th>\n",
       "      <td>buitl</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99476</th>\n",
       "      <td>holysmoke</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99477</th>\n",
       "      <td>richard_strauss</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99478</th>\n",
       "      <td>strauss_younger</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99479</th>\n",
       "      <td>strauss_elder</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99480 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word                                            Hyponym\n",
       "0                 sale  {realization, closeout, saleyard, presale, sal...\n",
       "1                 make  {makeless, makest, bring_about, overmake, make...\n",
       "2                  pay  {ypaid, paypig, payeth, pay_cash, paythrough, ...\n",
       "3                yukos                                                 {}\n",
       "4                   27                                                 {}\n",
       "...                ...                                                ...\n",
       "99475            buitl                                                 {}\n",
       "99476        holysmoke                                                 {}\n",
       "99477  richard_strauss                                                 {}\n",
       "99478  strauss_younger                                                 {}\n",
       "99479    strauss_elder                                                 {}\n",
       "\n",
       "[99480 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hyp=pd.read_pickle(\"salida/nuevo4a/Hyponyms.pickle\")\n",
    "df_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,strings in df_hyp.iterrows():\n",
    "    hyponyms[strings['word']]=strings['Hyponym']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(8):\n",
    "#     if i==0:\n",
    "#         df_syn = pd.read_pickle('salida/nuevo4a/RTE3/DEV_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "#     else:\n",
    "#         try:\n",
    "#             temp = pd.read_pickle('salida/nuevo4a/RTE3/DEV_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "#             df_syn=pd.concat([df_syn,temp])\n",
    "#         except:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(8):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/RTE3/TEST_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(8):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/GHS/GHS_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     if i ==0:\n",
    "#         df_syn = pd.read_pickle('salida/nuevo4a/SICK/DEV_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "#     else:\n",
    "#         try:\n",
    "#             temp = pd.read_pickle('salida/nuevo4a/SICK/DEV_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "#             df_syn=pd.concat([df_syn,temp])\n",
    "#         except:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(45):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/SICK/TRAIN_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/SICK/TEST_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     if i==0:\n",
    "#         df_syn = pd.read_pickle('salida/nuevo4a/SNLI/DEV/DEV_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "#     else:\n",
    "#         try:\n",
    "#             temp = pd.read_pickle('salida/nuevo4a/SNLI/DEV/DEV_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "#             df_syn=pd.concat([df_syn,temp])\n",
    "#         except:\n",
    "#             print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/SNLI/TEST/TEST_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(55):\n",
    "    if i==0:\n",
    "        df_syn = pd.read_pickle('salida/nuevo4a/SNLI/TRAIN10000/TRAIN_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "    else:\n",
    "        try:\n",
    "            temp = pd.read_pickle('salida/nuevo4a/SNLI/TRAIN10000/TRAIN_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "            df_syn=pd.concat([df_syn,temp])\n",
    "        except:\n",
    "            print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1):\n",
    "#     if i==0:\n",
    "#         df_syn = pd.read_pickle('salida/nuevo4a/RTEGLUE/TRAIN_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "#     else:\n",
    "#         try:\n",
    "#             temp = pd.read_pickle('salida/nuevo4a/RTEGLUE/TRAIN_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "#             df_syn=pd.concat([df_syn,temp])\n",
    "#         except:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/RTEGLUE/DEV_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_syn = pd.read_pickle('salida/nuevo4a/MultiNLI/DIAG/diagnostic-full.csv_Hyponym.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_syn = pd.read_pickle('salida/nuevo4a/MultiNLI/DEVM/DEV_1.csv_Hyponym.pickle')\n",
    "# temp = pd.read_pickle('salida/nuevo4a/MultiNLI/DEVMM/DEV_1.csv_Hyponym.pickle')\n",
    "# df_syn=pd.concat([df_syn,temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(40):\n",
    "#     try:\n",
    "#         temp = pd.read_pickle('salida/nuevo4a/MultiNLI/TRAIN/TRAIN_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "#         df_syn=pd.concat([df_syn,temp])\n",
    "#     except:\n",
    "#         print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Hyponym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sale</td>\n",
       "      <td>{realization, closeout, saleyard, presale, sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make</td>\n",
       "      <td>{makeless, makest, bring_about, make_king, ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pay</td>\n",
       "      <td>{ypaid, paypig, payeth, pay_cash, paythrough, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yukos</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178787</th>\n",
       "      <td>rockclimber</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178788</th>\n",
       "      <td>spiderwoman</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178789</th>\n",
       "      <td>boulevardier</td>\n",
       "      <td>{boulevardiering, boulevardiered, boulevardiers}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178790</th>\n",
       "      <td>prformance</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178791</th>\n",
       "      <td>chilldren</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2178792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word                                            Hyponym\n",
       "0                sale  {realization, closeout, saleyard, presale, sal...\n",
       "1                make  {makeless, makest, bring_about, make_king, ove...\n",
       "2                 pay  {ypaid, paypig, payeth, pay_cash, paythrough, ...\n",
       "3               yukos                                                 {}\n",
       "4                  27                                                 {}\n",
       "...               ...                                                ...\n",
       "2178787   rockclimber                                                 {}\n",
       "2178788   spiderwoman                                                 {}\n",
       "2178789  boulevardier   {boulevardiering, boulevardiered, boulevardiers}\n",
       "2178790    prformance                                                 {}\n",
       "2178791     chilldren                                                 {}\n",
       "\n",
       "[2178792 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_syn = df_syn.reset_index(drop=True)\n",
    "df_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn=df_syn.drop_duplicates('word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,strings in df_syn.iterrows():\n",
    "    hyponyms[strings['word']]=strings['Hyponym']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100345"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hyponyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[key, hyponyms[key]] for key in hyponyms.keys()], columns=['word', 'Hyponym'])\n",
    "df.to_pickle(\"salida/nuevo4a/Hyponyms.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checar diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Synonym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sale</td>\n",
       "      <td>{sale, sales_agreement, sales_event, cut_rate_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make</td>\n",
       "      <td>{relieve_oneself, fabricate, construction, dra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pay</td>\n",
       "      <td>{action, yield, pay_up, fee, make_up, give, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yukos</td>\n",
       "      <td>{yukos}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>{xxvii, twenty_seven, 27}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64407</th>\n",
       "      <td>nill</td>\n",
       "      <td>{nill}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64408</th>\n",
       "      <td>edin</td>\n",
       "      <td>{edin}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64409</th>\n",
       "      <td>merrigan</td>\n",
       "      <td>{merrigan}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64410</th>\n",
       "      <td>teleread</td>\n",
       "      <td>{teleread}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64411</th>\n",
       "      <td>ebert</td>\n",
       "      <td>{ebert}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64412 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word                                            Synonym\n",
       "0          sale  {sale, sales_agreement, sales_event, cut_rate_...\n",
       "1          make  {relieve_oneself, fabricate, construction, dra...\n",
       "2           pay  {action, yield, pay_up, fee, make_up, give, wa...\n",
       "3         yukos                                            {yukos}\n",
       "4            27                          {xxvii, twenty_seven, 27}\n",
       "...         ...                                                ...\n",
       "64407      nill                                             {nill}\n",
       "64408      edin                                             {edin}\n",
       "64409  merrigan                                         {merrigan}\n",
       "64410  teleread                                         {teleread}\n",
       "64411     ebert                                            {ebert}\n",
       "\n",
       "[64412 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sinonimos=pd.read_pickle(\"salida/nuevo4a/Synonyms.pickle\")\n",
    "df_sinonimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,strings in df_sinonimos.iterrows():\n",
    "    synonyms[strings['word']]=strings['Synonym']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64412"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperonyms=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Hyperonym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sale</td>\n",
       "      <td>{saloon, occasion, agreement, good_for_busines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make</td>\n",
       "      <td>{tidy, create_from_raw_material, software, pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pay</td>\n",
       "      <td>{settle, make, payment, give, person_now_paid,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yukos</td>\n",
       "      <td>{company, yuko}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88114</th>\n",
       "      <td>nill</td>\n",
       "      <td>{will, nebula, ne}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88115</th>\n",
       "      <td>edin</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88116</th>\n",
       "      <td>merrigan</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88117</th>\n",
       "      <td>teleread</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88118</th>\n",
       "      <td>ebert</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88119 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word                                          Hyperonym\n",
       "0          sale  {saloon, occasion, agreement, good_for_busines...\n",
       "1          make  {tidy, create_from_raw_material, software, pas...\n",
       "2           pay  {settle, make, payment, give, person_now_paid,...\n",
       "3         yukos                                    {company, yuko}\n",
       "4            27                                                 {}\n",
       "...         ...                                                ...\n",
       "88114      nill                                 {will, nebula, ne}\n",
       "88115      edin                                                 {}\n",
       "88116  merrigan                                                 {}\n",
       "88117  teleread                                                 {}\n",
       "88118     ebert                                                 {}\n",
       "\n",
       "[88119 rows x 2 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_h=pd.read_pickle(\"salida/nuevo4a/Hyperonyms.pickle\")\n",
    "df_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,strings in df_h.iterrows():\n",
    "    hyperonyms[strings['word']]=strings['Hyperonym']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88119"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hyperonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyponyms=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Hyponym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sale</td>\n",
       "      <td>{nonsale, saleworthy, wholesale, selloff, cut_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make</td>\n",
       "      <td>{distill, produce, claw, call_up, scrape, rema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pay</td>\n",
       "      <td>{payback, paypal, autopay, subsidize, payable,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yukos</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89769</th>\n",
       "      <td>edin</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89770</th>\n",
       "      <td>merrigan</td>\n",
       "      <td>{merrigans}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89771</th>\n",
       "      <td>teleread</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89772</th>\n",
       "      <td>extortioner</td>\n",
       "      <td>{extortioners}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89773</th>\n",
       "      <td>ebert</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89774 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word                                            Hyponym\n",
       "0             sale  {nonsale, saleworthy, wholesale, selloff, cut_...\n",
       "1             make  {distill, produce, claw, call_up, scrape, rema...\n",
       "2              pay  {payback, paypal, autopay, subsidize, payable,...\n",
       "3            yukos                                                 {}\n",
       "4               27                                                 {}\n",
       "...            ...                                                ...\n",
       "89769         edin                                                 {}\n",
       "89770     merrigan                                        {merrigans}\n",
       "89771     teleread                                                 {}\n",
       "89772  extortioner                                     {extortioners}\n",
       "89773        ebert                                                 {}\n",
       "\n",
       "[89774 rows x 2 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hi=pd.read_pickle(\"salida/nuevo4a/Hyponyms.pickle\")\n",
    "df_hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,strings in df_hi.iterrows():\n",
    "    hyponyms[strings['word']]=strings['Hyponym']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89774"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hyponyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'united_states', 'usonia'}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyponyms[\"united_states_of_america\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'united_states_of_america'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[158], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msynonyms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munited_states_of_america\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'united_states_of_america'"
     ]
    }
   ],
   "source": [
    "synonyms[\"united_states_of_america\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capitalist_democratic_federal_republic',\n",
       " 'country',\n",
       " 'country_within_world',\n",
       " 'in_north_america',\n",
       " 'one_of_many_countries',\n",
       " 'state'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperonimos[\"united_states_of_america\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"sale\" in hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    if i==0:\n",
    "        df_syn = pd.read_pickle('salida/nuevo4a/RTE3/DEV_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "    else:\n",
    "        try:\n",
    "            temp = pd.read_pickle('salida/nuevo4a/RTE3/DEV_'+str(i+1)+'.csv_Synonym.pickle')\n",
    "            df_syn=pd.concat([df_syn,temp])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Synonym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sale</td>\n",
       "      <td>{sale, sales_agreement, sales_event, cut_rate_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make</td>\n",
       "      <td>{fabricate, relieve_oneself, construction, dra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pay</td>\n",
       "      <td>{action, fee, yield, pay_up, make_up, give, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yukos</td>\n",
       "      <td>{yukos}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>{xxvii, twenty_seven, 27}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>casting</td>\n",
       "      <td>{cast, audition, molding, casting}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>quality</td>\n",
       "      <td>{accident, quality, gentry, upper_class, linea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>slab</td>\n",
       "      <td>{screed, slab}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>invest</td>\n",
       "      <td>{place, enthrone, invest, commit, vest, endow,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>cast</td>\n",
       "      <td>{draw, shed, roll, cast_of_characters, cast, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10909 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word                                            Synonym\n",
       "0        sale  {sale, sales_agreement, sales_event, cut_rate_...\n",
       "1        make  {fabricate, relieve_oneself, construction, dra...\n",
       "2         pay  {action, fee, yield, pay_up, make_up, give, wa...\n",
       "3       yukos                                            {yukos}\n",
       "4          27                          {xxvii, twenty_seven, 27}\n",
       "...       ...                                                ...\n",
       "1258  casting                 {cast, audition, molding, casting}\n",
       "1259  quality  {accident, quality, gentry, upper_class, linea...\n",
       "1260     slab                                     {screed, slab}\n",
       "1261   invest  {place, enthrone, invest, commit, vest, endow,...\n",
       "1262     cast  {draw, shed, roll, cast_of_characters, cast, s...\n",
       "\n",
       "[10909 rows x 2 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    if i==0:\n",
    "        df_hyp = pd.read_pickle('salida/nuevo4a/RTE3/DEV_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "    else:\n",
    "        try:\n",
    "            temp = pd.read_pickle('salida/nuevo4a/RTE3/DEV_'+str(i+1)+'.csv_Hyponym.pickle')\n",
    "            df_hyp=pd.concat([df_hyp,temp])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Hyponym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sale</td>\n",
       "      <td>{nonsale, saleworthy, wholesale, cut_rate_sale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make</td>\n",
       "      <td>{distill, produce, claw, call_up, scrape, rema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pay</td>\n",
       "      <td>{payback, paypal, subsidize, autopay, payable,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yukos</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>enthrone</td>\n",
       "      <td>{enthroning, enthronise, enthroneth, enthrones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>vest</td>\n",
       "      <td>{vested, vesteth, safety_vest, life_jacket, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>clothe</td>\n",
       "      <td>{clothest, overclothe, underclothe, clothes, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>endow</td>\n",
       "      <td>{cover, endoweth, endowing, well_endowed, bene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>induct</td>\n",
       "      <td>{inducts, inducting, reinduct, inducted, induc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word                                            Hyponym\n",
       "0         sale  {nonsale, saleworthy, wholesale, cut_rate_sale...\n",
       "1         make  {distill, produce, claw, call_up, scrape, rema...\n",
       "2          pay  {payback, paypal, subsidize, autopay, payable,...\n",
       "3        yukos                                                 {}\n",
       "4           27                                                 {}\n",
       "...        ...                                                ...\n",
       "2087  enthrone  {enthroning, enthronise, enthroneth, enthrones...\n",
       "2088      vest  {vested, vesteth, safety_vest, life_jacket, yo...\n",
       "2089    clothe  {clothest, overclothe, underclothe, clothes, c...\n",
       "2090     endow  {cover, endoweth, endowing, well_endowed, bene...\n",
       "2091    induct  {inducts, inducting, reinduct, inducted, induc...\n",
       "\n",
       "[16800 rows x 2 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guess',\n",
       " 'épopée',\n",
       " 'united_states_of_america',\n",
       " 'wretched',\n",
       " 'aggress',\n",
       " 'foremost',\n",
       " 'cast_of_characters',\n",
       " 'risk_of_infection',\n",
       " 'arabian_peninsula',\n",
       " 'strobile',\n",
       " 'excogitate',\n",
       " 'spent',\n",
       " 'outer_space',\n",
       " 'pieces',\n",
       " 'activeness',\n",
       " 'increment',\n",
       " 'know_as',\n",
       " 'wasted',\n",
       " 'contrived',\n",
       " 'come_out',\n",
       " 'break_up',\n",
       " 'oeuvre',\n",
       " 'knowingness',\n",
       " 'unexplored',\n",
       " 'phonemic_merger',\n",
       " 'radiotherapy',\n",
       " 'kayfabe',\n",
       " 'dramatize',\n",
       " 'birther',\n",
       " 'unfolding',\n",
       " 'brush',\n",
       " 'garbage_disposal',\n",
       " 'set_ahead',\n",
       " 'rain_forest',\n",
       " 'sobriquet',\n",
       " 'homage',\n",
       " 'harmonise',\n",
       " 'diluted',\n",
       " 'sabi',\n",
       " 'overtop',\n",
       " 'squeal',\n",
       " 'hellenic_republic',\n",
       " 'pentadecimal',\n",
       " 'fecund',\n",
       " 'reefer',\n",
       " 'diffuse',\n",
       " 'torso',\n",
       " 'guerilla',\n",
       " 'screen_name',\n",
       " 'flight_of_stairs',\n",
       " 'managing_director',\n",
       " 'sunshine_state',\n",
       " 'gw',\n",
       " 'department_of_commerce',\n",
       " 'dehorn',\n",
       " 'junk',\n",
       " 'come_to_pass',\n",
       " 'pressure_sensation',\n",
       " 'drastic',\n",
       " 'soccer',\n",
       " 'cartogram',\n",
       " 'state_of_matter',\n",
       " 'lay_aside',\n",
       " 'clasp',\n",
       " 'infant',\n",
       " 'careen',\n",
       " 'police_department',\n",
       " 'favorable_reception',\n",
       " 'han',\n",
       " 'case_by_case',\n",
       " 'digest',\n",
       " 'confer',\n",
       " 'vomit',\n",
       " 'put_in',\n",
       " 'organic_structure',\n",
       " 'deg',\n",
       " 'bank_building',\n",
       " 'holy_cross',\n",
       " 'domiciliate',\n",
       " 'shoot_down',\n",
       " 'give_hand',\n",
       " 'helpless',\n",
       " 'smutty',\n",
       " 'beget',\n",
       " 'move_on',\n",
       " 'outlooking',\n",
       " 'enormous',\n",
       " 'suitable',\n",
       " 'persist_in',\n",
       " 'phonograph_record',\n",
       " 'escritoire',\n",
       " 'break_off',\n",
       " 'find_oneself',\n",
       " 'slit',\n",
       " 'kanchanjanga',\n",
       " 'thousand_million',\n",
       " 'margaret_court',\n",
       " 'wogball',\n",
       " 'bribe',\n",
       " 'porcelain',\n",
       " 'papers',\n",
       " 'freeman',\n",
       " 'sorrel',\n",
       " 'vagina',\n",
       " 'try_on',\n",
       " 'typify',\n",
       " 'pithless',\n",
       " 'united_states',\n",
       " 'sinister',\n",
       " 'send_away',\n",
       " 'even_out',\n",
       " 'tierce',\n",
       " 'excessive',\n",
       " 'beck',\n",
       " 'disposition',\n",
       " 'founding_father',\n",
       " 'yank',\n",
       " 'unaffixed',\n",
       " 'piece_of_eight',\n",
       " 'republic_of_hungary',\n",
       " 'exalt',\n",
       " 'utmost',\n",
       " 'canvass',\n",
       " 'free_of_charge',\n",
       " 'dyke',\n",
       " 'routine',\n",
       " 'impart',\n",
       " 'imperil',\n",
       " 'tautness',\n",
       " 'additional',\n",
       " 'prophylactic',\n",
       " 'jiggambob',\n",
       " 'tobacco_plant',\n",
       " 'dyestuff',\n",
       " 'elevated',\n",
       " 'race_murder',\n",
       " 'reappearance',\n",
       " 'lucky_break',\n",
       " 'liever',\n",
       " 'arabian',\n",
       " 'cobalt',\n",
       " 'procure',\n",
       " 'motivate',\n",
       " 'incursion',\n",
       " 'theater_director',\n",
       " 'african_american',\n",
       " 'monetary_standard',\n",
       " 'u.s',\n",
       " 'proliferate',\n",
       " 'incline',\n",
       " 'us_ian',\n",
       " 'lodge',\n",
       " 'big_name',\n",
       " 'electric_current',\n",
       " 'cant',\n",
       " 'fabulator',\n",
       " 'helper',\n",
       " 'technic',\n",
       " 'fritter_away',\n",
       " 'torch',\n",
       " 'blossom',\n",
       " 'confine',\n",
       " 'coronet',\n",
       " 'octal',\n",
       " 'mushroomer',\n",
       " 'wishy_washy',\n",
       " 'stroke',\n",
       " 'multiservice',\n",
       " 'adjunct',\n",
       " 'haughty',\n",
       " 'skim',\n",
       " 'impediment',\n",
       " 'tremblor',\n",
       " 'possess',\n",
       " 'azrael',\n",
       " 'rain_cats_and_dogs',\n",
       " 'place_of_business',\n",
       " 'regular',\n",
       " 'accordance',\n",
       " 'commercialism',\n",
       " 'smoulder',\n",
       " 'picky',\n",
       " 'so_so',\n",
       " 'swart',\n",
       " 'sign_up',\n",
       " 'sporting',\n",
       " 'vincible',\n",
       " 'inexperienced',\n",
       " 'call_in',\n",
       " 'uttermost',\n",
       " 'other_than',\n",
       " 'fertilize',\n",
       " 'six_spot',\n",
       " 'match',\n",
       " 'musculus',\n",
       " \"get_under_one's_skin\",\n",
       " 'docking_facility',\n",
       " 'cunt',\n",
       " 'slap_bang',\n",
       " 'arab_republic_of_egypt',\n",
       " 'german_empire',\n",
       " 'expense',\n",
       " 'conserve',\n",
       " 'unloosen',\n",
       " 'public_speaking',\n",
       " 'soviet_union',\n",
       " 'severity',\n",
       " 'edifice',\n",
       " 'commitment',\n",
       " 'contrarily',\n",
       " 'promptly',\n",
       " 'regulative',\n",
       " 'timberland',\n",
       " \"keep_one's_word\",\n",
       " 'adjute',\n",
       " 'connivance',\n",
       " 'gum',\n",
       " 'signboard',\n",
       " 'assimilate',\n",
       " 'wraith',\n",
       " 'make_use',\n",
       " 'micturate',\n",
       " 'crippled',\n",
       " 'complicate',\n",
       " 'tome',\n",
       " 'ˈ',\n",
       " 'stay_fresh',\n",
       " 'spurn',\n",
       " 'astroboffin',\n",
       " 'lead_out',\n",
       " 'offstage',\n",
       " 'ejaculate',\n",
       " 'authenticity',\n",
       " 'operative',\n",
       " 'breakout',\n",
       " 'country_music',\n",
       " 'timber',\n",
       " 'west_germany',\n",
       " 'chronicle',\n",
       " 'unease',\n",
       " 'crack',\n",
       " 'dissolve',\n",
       " 'disable',\n",
       " 'german_language',\n",
       " 'legion',\n",
       " 'co_op',\n",
       " 'due_south',\n",
       " 'dent',\n",
       " 'n_speed_automatic',\n",
       " 'high_toned',\n",
       " 'augury',\n",
       " 'lease',\n",
       " 'partly',\n",
       " 'coupling',\n",
       " 'sweetie_pie',\n",
       " 'gueridon',\n",
       " 'meanspirited',\n",
       " 'gathered',\n",
       " 'bet_on',\n",
       " 'sales_activity',\n",
       " 'hummel',\n",
       " 'unite',\n",
       " 'chest',\n",
       " 'born_again',\n",
       " 'polygamous',\n",
       " 'ingredient',\n",
       " 'shut_up',\n",
       " 'first_of_all',\n",
       " 'be',\n",
       " 'mellow',\n",
       " 'day_off',\n",
       " 'authorization',\n",
       " 'send_off',\n",
       " 'thenar',\n",
       " 'est',\n",
       " 'unsatisfactory',\n",
       " 'rectification',\n",
       " 'solid_ground',\n",
       " 'sion',\n",
       " 'offspring',\n",
       " 'annex',\n",
       " 'in_south',\n",
       " 'mood',\n",
       " 'discourse',\n",
       " 'discount',\n",
       " 'concurrent',\n",
       " 'piddle',\n",
       " 'victualler',\n",
       " 'limitation',\n",
       " 'gram',\n",
       " 'mould',\n",
       " 'linguistic_communication',\n",
       " 'veracious',\n",
       " 'lead_off',\n",
       " 'give_way',\n",
       " 'italia',\n",
       " 'equalizer',\n",
       " 'womanhood',\n",
       " 'adjutor',\n",
       " 'unification',\n",
       " 'sack',\n",
       " 'roentgen',\n",
       " 'find_out',\n",
       " 'united_states_president',\n",
       " 'confiscate',\n",
       " 'saudi_arabian',\n",
       " 'serving',\n",
       " 'odorant',\n",
       " 'unleash',\n",
       " 'low_down',\n",
       " 'soaring',\n",
       " 'exemplary',\n",
       " 'strange',\n",
       " 'virgo_intacta',\n",
       " 'rotten',\n",
       " 'woodentop',\n",
       " 'remain_firm',\n",
       " 'start_up',\n",
       " 'garland',\n",
       " 'call_off',\n",
       " 'point_of_view',\n",
       " 'rest_his_soul',\n",
       " 'weedy',\n",
       " \"i've\",\n",
       " 'unsound',\n",
       " 'oxo',\n",
       " 'enclose',\n",
       " 'bugle',\n",
       " 'stamp_out',\n",
       " 'junction',\n",
       " 'procession',\n",
       " 'time_out',\n",
       " 'deterioration',\n",
       " 'triad',\n",
       " 'expectant',\n",
       " 'burn_mark',\n",
       " 'shoes',\n",
       " 'universal_set',\n",
       " 'stimulate',\n",
       " 'high_risk',\n",
       " 'strobilus',\n",
       " 'downspout',\n",
       " 'sourstuff',\n",
       " 'tough',\n",
       " 'currentest',\n",
       " 'atomic_number_82',\n",
       " 'grasp',\n",
       " 'destitute',\n",
       " 'scale_of_measurement',\n",
       " 'disputation',\n",
       " 'nine_spot',\n",
       " 'disseminate',\n",
       " 'eke',\n",
       " 'broadly',\n",
       " 'argue',\n",
       " 'earthdin',\n",
       " 'roy_wilkins',\n",
       " 'splenetic',\n",
       " 'mushroom',\n",
       " 'soberly',\n",
       " 'pennant',\n",
       " 'conversion',\n",
       " 'cruelly',\n",
       " 'touchy',\n",
       " 'line_up',\n",
       " 'financial_support',\n",
       " 'vile',\n",
       " 'personnel',\n",
       " 'great_britain',\n",
       " 'radius',\n",
       " 'youthful',\n",
       " 'rain_buckets',\n",
       " 'step_up',\n",
       " 'clime',\n",
       " 'grammatical_case',\n",
       " 'join_forces',\n",
       " 'comparative',\n",
       " 'backing',\n",
       " 'skillfulness',\n",
       " 'bits',\n",
       " 'wither',\n",
       " 'chosenness',\n",
       " 'pinch',\n",
       " 'misfire',\n",
       " 'quarrel',\n",
       " 'republic_of_peru',\n",
       " 'impeccable',\n",
       " 'terminate',\n",
       " 'egyptian_empire',\n",
       " 'let_loose',\n",
       " 'self_shifting_transmission',\n",
       " 'missionary_post',\n",
       " 'peddle',\n",
       " 'splice',\n",
       " 'personify',\n",
       " 'daydream',\n",
       " 'swear_out',\n",
       " 'prexy',\n",
       " 'branch_out',\n",
       " 'tall',\n",
       " 'slay',\n",
       " 'strengthless',\n",
       " 'self_propelled',\n",
       " 'because',\n",
       " 'copper',\n",
       " 'generator',\n",
       " 'john_roy_major',\n",
       " 'wield',\n",
       " 'rid',\n",
       " 'edwin_powell_hubble',\n",
       " 'usually',\n",
       " 'contend',\n",
       " 'demote',\n",
       " 'stew',\n",
       " 'cave_in',\n",
       " 'comedown',\n",
       " 'illogical',\n",
       " 'k',\n",
       " 'sylva',\n",
       " 'hydroxic_acid',\n",
       " 'utilization',\n",
       " 'vote_out',\n",
       " 'specter',\n",
       " 'okay',\n",
       " 'take_into_account',\n",
       " \"meet_one's_maker\",\n",
       " 'xor',\n",
       " 'shiite',\n",
       " 'earwax',\n",
       " 'wildmeat',\n",
       " 'localize',\n",
       " 'go_up',\n",
       " 'lunar_month',\n",
       " 'passing_water',\n",
       " 'slender',\n",
       " 'payoff',\n",
       " 'cathay',\n",
       " 'golf_hole',\n",
       " 'muscular_tissue',\n",
       " 'received',\n",
       " 'bearer',\n",
       " 'whatdoyoucallit',\n",
       " 'artificer',\n",
       " 'cerumen',\n",
       " 'pregnancy',\n",
       " 'span',\n",
       " 'degeneracy',\n",
       " 'crag',\n",
       " 'tetradecimal',\n",
       " 'renounce',\n",
       " 'dubious',\n",
       " 'send_packing',\n",
       " 'radiate',\n",
       " 'surround',\n",
       " 'domestic_help',\n",
       " 'lather',\n",
       " 'tumultuous',\n",
       " 'cognisance',\n",
       " 'vulgar',\n",
       " 'affaire',\n",
       " 'clam',\n",
       " 'crabbed',\n",
       " 'roll_down',\n",
       " 'threesome',\n",
       " 'compensate',\n",
       " 'bide',\n",
       " 'revenue_enhancement',\n",
       " 'time_of_day',\n",
       " 'padre',\n",
       " 'plaster_cast',\n",
       " 'unfreedom',\n",
       " 'incandesce',\n",
       " 'easy_lay',\n",
       " 'faction',\n",
       " 'limb',\n",
       " 'societal',\n",
       " 'stand_for',\n",
       " 'epithet',\n",
       " 'dutchland',\n",
       " 'accompaniment',\n",
       " 'slugger',\n",
       " 'star_topology',\n",
       " 'stalinism',\n",
       " 'encompass',\n",
       " 'rugby_football',\n",
       " 'put_on',\n",
       " 'earmark',\n",
       " 'degenerate',\n",
       " 'lowly',\n",
       " 'flange',\n",
       " 'automatic',\n",
       " 'pass_away',\n",
       " 'difference_of_opinion',\n",
       " 'juxtapose',\n",
       " 'have_effect',\n",
       " 'waxen',\n",
       " 'bender',\n",
       " 'superior_general',\n",
       " 'promiscuous',\n",
       " 'united_statesian',\n",
       " 'cone_shape',\n",
       " 'fable',\n",
       " 'cater',\n",
       " 'assigned_servant',\n",
       " 'feed_in',\n",
       " 'soapie',\n",
       " 'depone',\n",
       " 'should',\n",
       " 'microseism',\n",
       " 'presumptive',\n",
       " 'stocktaking',\n",
       " 'peril',\n",
       " 'twelvemonth',\n",
       " 'surmount',\n",
       " 'burgess',\n",
       " 'take_part',\n",
       " 'phone_call',\n",
       " 'intermediate',\n",
       " 'motor_hotel',\n",
       " 'assent',\n",
       " 'ball_shaped',\n",
       " 'interbred',\n",
       " 'colossal',\n",
       " 'gifted',\n",
       " 'hold_up',\n",
       " 'sever',\n",
       " 'celestial_empire',\n",
       " 'cauterize',\n",
       " 'motherliness',\n",
       " 'sheath',\n",
       " 'glow',\n",
       " 'administrative_segregation',\n",
       " 'bring_back',\n",
       " 'pamper',\n",
       " 'manumit',\n",
       " 'politics',\n",
       " 'decease',\n",
       " 'proline',\n",
       " 'mention',\n",
       " 'sr',\n",
       " 'oftenly',\n",
       " 'pedestal',\n",
       " 'constitute',\n",
       " 'dockage',\n",
       " 'megabyte',\n",
       " 'protrude',\n",
       " 'garner',\n",
       " 'participation',\n",
       " 'natural_process',\n",
       " 'take_away',\n",
       " 'embarrass',\n",
       " 'showcase',\n",
       " 'dilute',\n",
       " 'algorithm',\n",
       " 'butt',\n",
       " 'bareass',\n",
       " 'runnel',\n",
       " 'aggrandize',\n",
       " 'flimsy',\n",
       " 'britanny',\n",
       " 'impulse',\n",
       " 'come_to',\n",
       " 'brush_off',\n",
       " 'enrollment',\n",
       " 'hare',\n",
       " 'elevate',\n",
       " 'camiknickers',\n",
       " 'come_about',\n",
       " 'con',\n",
       " 'traverse',\n",
       " 'buffet',\n",
       " 'al_qaeda',\n",
       " 'swallow',\n",
       " 'old_fashioned',\n",
       " 'whole_tone',\n",
       " 'posture',\n",
       " 'feat',\n",
       " 'rehi',\n",
       " 'right_angle',\n",
       " 'afforest',\n",
       " 'issue_forth',\n",
       " 'concerted',\n",
       " 'connectedness',\n",
       " 'ataraxis',\n",
       " 'distaff',\n",
       " 'lapse',\n",
       " 'transversal',\n",
       " 'purpose',\n",
       " 'distribute',\n",
       " 'wizard',\n",
       " 'prepositus',\n",
       " 'polarity',\n",
       " 'ersatz',\n",
       " 'first_class_honours_degree',\n",
       " 'dematerialize',\n",
       " 'provost',\n",
       " 'measureless',\n",
       " 'trash',\n",
       " 'baccy',\n",
       " 'bloom',\n",
       " 'right_to_vote',\n",
       " 'crusade',\n",
       " 'exploitation',\n",
       " 'articulate',\n",
       " 'schism',\n",
       " 'nowaday',\n",
       " 'i',\n",
       " 'adjudicate',\n",
       " 'state_of_israel',\n",
       " 'crimination',\n",
       " 'financial_backing',\n",
       " 'blastoff',\n",
       " 'unsustained',\n",
       " 'dormitory',\n",
       " 'enlist',\n",
       " 'salvage',\n",
       " 'united_kingdom',\n",
       " '1st',\n",
       " 'underprop',\n",
       " 'dr_congo',\n",
       " 'wargame',\n",
       " 'john_rock',\n",
       " 'have_high_regard_for',\n",
       " 'gaolbreak',\n",
       " 'agitate',\n",
       " 'eminent',\n",
       " 'timeline',\n",
       " 'maiden_over',\n",
       " 'embolden',\n",
       " 'sixer',\n",
       " 'cognitive_operation',\n",
       " 'die_out',\n",
       " 'frame',\n",
       " 'twitch',\n",
       " 'prison_term',\n",
       " 'labor_union',\n",
       " 'misfortune',\n",
       " 'deferred_payment',\n",
       " 'tenseness',\n",
       " 'hark_back',\n",
       " 'affirm',\n",
       " 'backstage',\n",
       " 'military_position',\n",
       " 'proud',\n",
       " 'break_away',\n",
       " 'fall_out',\n",
       " 'fall_apart',\n",
       " 'countryman',\n",
       " 'water_down',\n",
       " 'bazaar',\n",
       " 'turn_loss',\n",
       " 'accession',\n",
       " 'deserve',\n",
       " 'personate',\n",
       " 'inconclusive',\n",
       " 'diminish',\n",
       " 'avert',\n",
       " 'rock_candy',\n",
       " 'hydroxyl_acid',\n",
       " 'tincture',\n",
       " 'lousy',\n",
       " 'cccp',\n",
       " 'interrupt',\n",
       " 'communist_china',\n",
       " 'fashionable',\n",
       " 'idle',\n",
       " 'parting',\n",
       " 'slap',\n",
       " 'hexad',\n",
       " 'lump',\n",
       " 'rip',\n",
       " 'alice',\n",
       " 'platform',\n",
       " 'assert',\n",
       " 'each',\n",
       " 'uracil',\n",
       " 'bring_forth',\n",
       " 'finglish',\n",
       " 'scotch',\n",
       " 'seeland',\n",
       " 'diminution',\n",
       " 'arithmetic_mean',\n",
       " 'asylum',\n",
       " 'jacket',\n",
       " 'wipe_out',\n",
       " 'crumble',\n",
       " 'prop',\n",
       " 'uniting',\n",
       " 'spectre',\n",
       " 'lines',\n",
       " 'cathexis',\n",
       " 'prospect',\n",
       " 'soundbox',\n",
       " 'morose',\n",
       " 'av',\n",
       " 'dm',\n",
       " 'abominable',\n",
       " 'in_advance',\n",
       " 'mgt',\n",
       " 'predominate',\n",
       " 'broach',\n",
       " 'residential_district',\n",
       " 'garbage',\n",
       " 'marketplace',\n",
       " 'koweit',\n",
       " 'prisoners_bars',\n",
       " 'stoned',\n",
       " 'good_luck',\n",
       " 'termination',\n",
       " 'ferment',\n",
       " 'be_known_as',\n",
       " 'animate_being',\n",
       " 'straddle',\n",
       " 'devise',\n",
       " 'crown_of_thorns',\n",
       " 'neglect',\n",
       " 'toss_off',\n",
       " 'round_trip',\n",
       " 'in_operation',\n",
       " 'serve_up',\n",
       " 'get_going',\n",
       " 'item',\n",
       " 'runlet',\n",
       " 'grievous_bodily_harm',\n",
       " 'automatonlike',\n",
       " 'baggy',\n",
       " \"planck's_constant\",\n",
       " 'wee',\n",
       " 'collar',\n",
       " 'proceeds',\n",
       " 'preclude',\n",
       " 'particular_proposition',\n",
       " 'father_god',\n",
       " 'reenact',\n",
       " 'throw_out',\n",
       " 'become_flat',\n",
       " 'intimacy',\n",
       " 'probable',\n",
       " 'sith',\n",
       " 'kingdom_of_spain',\n",
       " 'twelve',\n",
       " 'unfettered',\n",
       " 'declamatory',\n",
       " 'scrap',\n",
       " 'soil',\n",
       " '1000000000',\n",
       " 'ten_spot',\n",
       " 'scale_leaf',\n",
       " 'proc',\n",
       " 'chiefery',\n",
       " 'take_up',\n",
       " 'unkiddingly',\n",
       " 'trouble',\n",
       " 'prime_number',\n",
       " 'casing',\n",
       " 'dictatorialism',\n",
       " 'be_able_to',\n",
       " 'headliner',\n",
       " 'shade',\n",
       " 'abide',\n",
       " 'dumping',\n",
       " 'stay_put',\n",
       " 'economize',\n",
       " 'bring_out',\n",
       " 'circulate',\n",
       " 'peeps',\n",
       " 'gratuitous',\n",
       " 'make_buy',\n",
       " 'executive_director',\n",
       " 'insinuate',\n",
       " 'essence',\n",
       " 'meditation',\n",
       " 'disc',\n",
       " 'reclaim',\n",
       " 'armorial_bearing',\n",
       " 'overspread',\n",
       " 'gravely',\n",
       " 'pride',\n",
       " 'mind',\n",
       " 'racial_extermination',\n",
       " 'authorities',\n",
       " 'emit',\n",
       " 'terminology',\n",
       " 'juncture',\n",
       " 'senseless',\n",
       " 'amongst_other_things',\n",
       " 'complimentary',\n",
       " 'fledge',\n",
       " 'unitary',\n",
       " 'call_option',\n",
       " 'dodgy',\n",
       " 'deficiency',\n",
       " 'impeach',\n",
       " 'companionship',\n",
       " 'nontaxable',\n",
       " 'roll_in_hay',\n",
       " 'smear',\n",
       " 'two_hundred',\n",
       " 'state_police',\n",
       " 'adorn',\n",
       " 'depreciate',\n",
       " 'fractious',\n",
       " 'whatsoever',\n",
       " 'oblique',\n",
       " 'declension',\n",
       " 'modeling',\n",
       " 'orb',\n",
       " 'without',\n",
       " 'dapple',\n",
       " 'exemplify',\n",
       " 'commend',\n",
       " 'nascent',\n",
       " 'come_to_end',\n",
       " 'decrease',\n",
       " 'yielding',\n",
       " 'these_days',\n",
       " 'brotherhood',\n",
       " 'hydroxilic_acid',\n",
       " 'severe',\n",
       " 'do_work',\n",
       " 'dissociate',\n",
       " 'white_house',\n",
       " 'affliction',\n",
       " 'wavering',\n",
       " 'asterisk',\n",
       " 'nondescript',\n",
       " 'friar',\n",
       " 'flank',\n",
       " 'inaugurate',\n",
       " 'buddy',\n",
       " 'dopesauce',\n",
       " 'floor',\n",
       " 'conk',\n",
       " 'maid',\n",
       " 'stuff',\n",
       " 'they',\n",
       " 'vernacular',\n",
       " 'terzetto',\n",
       " 'stall',\n",
       " 'doing',\n",
       " 'devote',\n",
       " 'general_officer',\n",
       " 'go_in',\n",
       " 'agone',\n",
       " 'reenforcement',\n",
       " 'no_amount',\n",
       " 'verge',\n",
       " 'detention',\n",
       " 'flying',\n",
       " 'constabulary',\n",
       " 'representing',\n",
       " \"shoemaker's_last\",\n",
       " 'berth',\n",
       " 'north_german_confederation',\n",
       " 'slant',\n",
       " 'oddment',\n",
       " 'cudgel',\n",
       " 'military_campaign',\n",
       " 'cremate',\n",
       " 'astronomist',\n",
       " 'vest',\n",
       " 'caser',\n",
       " 'edge',\n",
       " 'inelasticity',\n",
       " 'gotthold_ephraim_lessing',\n",
       " 'conglutination',\n",
       " 'dignify',\n",
       " 'cush_cush',\n",
       " 'ice_cream_cone',\n",
       " 'yard',\n",
       " 'unpackaged',\n",
       " 'chelek',\n",
       " 'teardrop',\n",
       " 'butt_on',\n",
       " 'monetary_value',\n",
       " 'os',\n",
       " 'transgress',\n",
       " 'endangerment',\n",
       " 'glasshouse',\n",
       " 'cop_it',\n",
       " 'brand_new',\n",
       " 'square_metre',\n",
       " 'some_extent',\n",
       " 'new_high_german',\n",
       " 'funner',\n",
       " 'aftereffect',\n",
       " 'pyrotechnic',\n",
       " 'send_for',\n",
       " 'come_across',\n",
       " 'serenity',\n",
       " 'dollar_bill',\n",
       " 'silly',\n",
       " 'take_hold',\n",
       " 'state_trooper',\n",
       " 'formulator',\n",
       " 'alfred_bernhard_nobel',\n",
       " 'police_service',\n",
       " 'gridiron',\n",
       " 'well_intentioned',\n",
       " 'assail',\n",
       " 'record_book',\n",
       " 'badly',\n",
       " 'airs',\n",
       " 'sportfishing',\n",
       " 'touchstone',\n",
       " 'laminitis',\n",
       " 'affected_role',\n",
       " 'inky',\n",
       " 'habit',\n",
       " 'authorized',\n",
       " 'commoner',\n",
       " 'usual',\n",
       " 'tithe',\n",
       " 'choke',\n",
       " 'crown_attorney',\n",
       " 'impression',\n",
       " 'recoil',\n",
       " 'military_headquarters',\n",
       " 'opaquest',\n",
       " 'feast',\n",
       " 'recess',\n",
       " 'brigham_young',\n",
       " 'leverage',\n",
       " 'clothes',\n",
       " 'tuk_tuk',\n",
       " 'role_model',\n",
       " 'tint',\n",
       " 'tenth',\n",
       " 'faith',\n",
       " 'liquid_ecstasy',\n",
       " 'renovate',\n",
       " 'indiscreet',\n",
       " 'phase_modulation',\n",
       " 'tungsten',\n",
       " 'broil',\n",
       " 'freshly',\n",
       " 'footy',\n",
       " 'stance',\n",
       " 'crusty',\n",
       " 'lay_off',\n",
       " 'ordered_series',\n",
       " 'stage_business',\n",
       " 'firstly',\n",
       " 'monarchy',\n",
       " 'french_republic',\n",
       " 'pour_down',\n",
       " 'ane',\n",
       " 'admirable_crichton',\n",
       " 'embark',\n",
       " 'mannequin',\n",
       " 'bargain',\n",
       " 'saturnia_pavonia',\n",
       " 'yesteryear',\n",
       " 'all_kidding_aside',\n",
       " 'dominance',\n",
       " 'apprehend',\n",
       " 'push_forward',\n",
       " 'governing',\n",
       " 'spouse',\n",
       " 'coinage',\n",
       " 'unrecorded',\n",
       " 'utilise',\n",
       " 'hang_onto',\n",
       " 'administrator',\n",
       " 'ulterior',\n",
       " 'implosion_therapy',\n",
       " 'cross_fertilize',\n",
       " 'drop_dead',\n",
       " 'selvedge',\n",
       " 'gin',\n",
       " 'emperor_butterfly',\n",
       " 'defendant',\n",
       " 'donjon',\n",
       " 'expenditure',\n",
       " 'dexter',\n",
       " 'unfavorable',\n",
       " 'fretful',\n",
       " 'defective',\n",
       " 'ledger',\n",
       " 'file',\n",
       " 'ailing',\n",
       " 'trio',\n",
       " 'take_out',\n",
       " 'dish',\n",
       " 'diadem',\n",
       " 'ternary',\n",
       " 'take_leak',\n",
       " 'take_field',\n",
       " 'disengage',\n",
       " 'incidental',\n",
       " 'impost',\n",
       " 'deficient',\n",
       " 'explication',\n",
       " 'scratch_line',\n",
       " 'stead',\n",
       " 'kick_bucket',\n",
       " 'think_well_of',\n",
       " 'neighborly',\n",
       " 'fl',\n",
       " 'populace',\n",
       " ...}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_hyp[\"word\"]).difference(set(df_syn[\"word\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
